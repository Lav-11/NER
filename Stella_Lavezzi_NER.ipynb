{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2451a21b",
   "metadata": {},
   "source": [
    "# General information\n",
    "Francesco Stella 2124359, Computer Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de734ab",
   "metadata": {},
   "source": [
    "# CoNLL 2003 Dataset\n",
    "\n",
    "For this project, we used the CoNLL-2003 shared task dataset on language-independent named entity recognition (NER). This dataset includes annotated data for two languages, German and English, but we exclusively used the English portion for training and testing.\n",
    "\n",
    "The English data is sourced from the Reuters Corpus, comprising newswire articles published between August 1996 and August 1997. Specifically, the training set consists of articles from a ten-day period toward the end of August 1996, while the test set includes articles from December 1996.\n",
    "\n",
    "Each token in the dataset is annotated with one of the following four named entity types:\n",
    "\n",
    "* PER – Person\n",
    "* ORG – Organization\n",
    "* LOC – Location\n",
    "* MISC – Miscellaneous entities not covered by the other categories\n",
    "* O – Outside of a named entity\n",
    "\n",
    "The CoNLL-2003 dataset is widely regarded as a benchmark for evaluating NER systems due to its standardized format, high-quality annotations, and well-defined evaluation protocol (typically based on precision, recall, and F1-score). It continues to serve as a critical resource for comparing both traditional machine learning and modern deep learning approaches in sequence labeling tasks.\n",
    "\n",
    "Using the Hugging Face Datasets library, we imported the dataset in JSON format, where each instance contains the following fields:\n",
    "\n",
    "* id – The identifier of the sample\n",
    "* tokens – A list containing the tokenized sentence\n",
    "* pos_tags – A list of part-of-speech (POS) tags associated with each token\n",
    "* chunk_tags – A list of syntactic chunk tags\n",
    "* ner_tags – A list of named entity recognition tags corresponding to the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "975fa0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: {'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n",
      "\n",
      "Training set size: 14041\n",
      "Validation set size: 3250\n",
      "Test set size: 3453\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(0)\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"eriktks/conll2003\")\n",
    "\n",
    "# Access the train, validation, and test splits\n",
    "train_data = dataset[\"train\"]\n",
    "validation_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# Sample\n",
    "print(\"Example:\", train_data[0])\n",
    "print(\"\\nTraining set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(validation_data))\n",
    "print(\"Test set size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a098f6",
   "metadata": {},
   "source": [
    "For both the training and testing phases, we used seed 0 to ensure reproducibility, and the samples were taken from the training and test splits provided by the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b7960",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "## Google library\n",
    "The Google Gen AI Python SDK provides an interface for integrating Google's generative models into Python applications. We used this library because we tested our prompts using Gemma 3. The SDK offers access to a variety of large language models from Google, through a user-friendly structure and flexible configuration options. It supports features such as adjusting the temperature for response creativity and sending batch requests for more efficient processing.\n",
    "\n",
    "## Hugging Face\n",
    "Hugging Face is a leading machine learning and data science platform and community that enables users to build, train, and deploy machine learning models with ease. It offers a wide range of pretrained large language models (LLMs) that can be used for tasks such as text generation, summarization, translation, classification, and more.\n",
    "\n",
    "Developers can also fine-tune these models on custom datasets or even build new models from scratch using the tools provided by Hugging Face. A key component of the platform is the Transformers library, which we used in this project. It provides seamless integration with popular deep learning frameworks like PyTorch and TensorFlow, making it easier to experiment and scale models across different environments.\n",
    "\n",
    "In addition to models, Hugging Face hosts datasets such as CoNLL2003.\n",
    "\n",
    "## SeqEval\n",
    "Seqeval is a Python library designed for evaluating sequence labeling tasks, such as Named Entity Recognition (NER), Part-of-Speech (POS) tagging, and chunking. It provides a simple and efficient way to compute standard evaluation metrics, including precision, recall, and F1-score, specifically tailored for structured prediction tasks where labels follow formats like IOB/IOB2. We adopt this library to evaluate our results and compare the various methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7e6443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seqeval in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from seqeval) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-generativeai in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (2.25.0rc1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (2.169.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (2.40.0)\n",
      "Requirement already satisfied: protobuf in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (2.11.1)\n",
      "Requirement already satisfied: tqdm in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-genai\n",
    "%pip install seqeval\n",
    "%pip install google-generativeai\n",
    "%pip install ipywidgets --upgrade\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425123a",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "For the development and evaluation of the prompts in this project, we used two different large language models: Gemma 3 (27B) and DeepSeek.\n",
    "\n",
    "## Gemma 3 (27b)\n",
    "\n",
    "We chose Gemma 3 because it is a recently released model by Google, offering several notable advantages:\n",
    "\n",
    "* Computational efficiency: Gemma 3 is a relatively lightweight model that achieves reasonable performance compared to state-of-the-art (SOTA) models like Gemini 2.5 Pro, which has over ten times more parameters.\n",
    "* API limits: Unlike many other models with free-tier APIs, Gemma 3 allows for a higher number of requests per day, making it more suitable for iterative development and testing.\n",
    "\n",
    "However, these advantages come with a significant trade-off:\n",
    "\n",
    "* Lower performance: In our tests, Gemma 3 underperformed compared to more advanced models. When evaluated against Gemini 2.0 Flash, we observed a performance gap of up to 20% in F1-score. Despite this, using higher-performing models was impractical due to API rate limitations, which would have required a considerable amount of additonal time to complete equivalent testing. \n",
    "\n",
    "The lower accuracy of Gemma 3 also influenced our implementation: model outputs required additional validation and post-processing. In some cases, responses did not adhere to the expected output format, necessitating extra checks and error handling in our code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87739fc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
