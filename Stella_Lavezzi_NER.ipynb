{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2451a21b",
   "metadata": {},
   "source": [
    "## Master degree in Computer Engineering (Ai & Robotics)\n",
    "\n",
    "**Stella Francesco 2124359** \\\n",
    "**Lavezzi Luca 2154256**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e7e672",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "In this notebook we address the task of Named-Entity Recognition (NER), which consists in identifying and classifying entities such as persons, organizations, locations, and miscellaneous names within text. NER is a fundamental problem in Natural Language Processing (NLP), with applications ranging from information extraction to question answering.\n",
    "\n",
    "For our experiments, we use the widely adopted CoNLL-2003 dataset, which contains annotated newswire articles with four types of named entities: persons, organizations, locations, and miscellaneous. This dataset is a standard benchmark for evaluating NER systems in the general domain.\n",
    "\n",
    "To explore zero(few)-shot NER, we experiment with two instruction-tuned large language models (LLMs): **Gemma 3-27b-it**, which is accessed via API, and **DeepSeek-R1:14b**, which is executed locally using the Ollama framework.\n",
    "\n",
    "Following the guidelines of the project, we implement and evaluate the baseline method from Xie et al. (2023), as well as one additional zero-shot prompting strategy inspired by their work. We refine our prompts and methods using a training split of the dataset, and report results on a separate test split, following best practices for NER evaluation.\n",
    "\n",
    "The notebook is organized as follows:\n",
    "\n",
    "- Introduction of the dataset and domain\n",
    "- Documentation of any additional annotation or external libraries used\n",
    "- Introduction to the models used\n",
    "- Description of each zero(few)-shot method\n",
    "- Evaluation and critical discussion of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de734ab",
   "metadata": {},
   "source": [
    "# CoNLL 2003 Dataset\n",
    "\n",
    "For this project, we used the CoNLL-2003 shared task dataset on language-independent named entity recognition (NER). This dataset includes annotated data for two languages, German and English, but we exclusively used the English portion for training and testing.\n",
    "\n",
    "The English data is sourced from the Reuters Corpus, comprising newswire articles published between August 1996 and August 1997. Specifically, the training set consists of articles from a ten-day period toward the end of August 1996, while the test set includes articles from December 1996.\n",
    "\n",
    "Each token in the dataset is annotated with one of the following four named entity types:\n",
    "\n",
    "* PER – Person\n",
    "* ORG – Organization\n",
    "* LOC – Location\n",
    "* MISC – Miscellaneous entities not covered by the other categories\n",
    "* O – Outside of a named entity\n",
    "\n",
    "The CoNLL-2003 dataset is widely regarded as a benchmark for evaluating NER systems due to its standardized format, high-quality annotations, and well-defined evaluation protocol (typically based on precision, recall, and F1-score). It continues to serve as a critical resource for comparing both traditional machine learning and modern deep learning approaches in sequence labeling tasks.\n",
    "\n",
    "Using the Hugging Face Datasets library, we imported the dataset in JSON format, where each instance contains the following fields:\n",
    "\n",
    "* id – The identifier of the sample\n",
    "* tokens – A list containing the tokenized sentence\n",
    "* pos_tags – A list of part-of-speech (POS) tags associated with each token\n",
    "* chunk_tags – A list of syntactic chunk tags\n",
    "* ner_tags – A list of named entity recognition tags corresponding to the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975fa0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: {'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n",
      "\n",
      "Training set size: 14041\n",
      "Validation set size: 3250\n",
      "Test set size: 3453\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(0)\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"eriktks/conll2003\")\n",
    "\n",
    "# Access the train, validation, and test splits\n",
    "train_data = dataset[\"train\"]\n",
    "validation_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# Sample\n",
    "print(\"Example:\", train_data[0])\n",
    "print(\"\\nTraining set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(validation_data))\n",
    "print(\"Test set size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a098f6",
   "metadata": {},
   "source": [
    "For both the training and testing phases, we used seed 0 to ensure reproducibility, and the samples were taken from the training and test splits provided by the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b7960",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "## Google library\n",
    "The Google Gen AI Python SDK provides an interface for integrating Google's generative models into Python applications. We used this library because we tested our prompts using Gemma 3. The SDK offers access to a variety of large language models from Google, through a user-friendly structure and flexible configuration options. It supports features such as adjusting the temperature for response creativity and sending batch requests for more efficient processing.\n",
    "\n",
    "## Hugging Face\n",
    "Hugging Face is a leading machine learning and data science platform and community that enables users to build, train, and deploy machine learning models with ease. It offers a wide range of pretrained large language models (LLMs) that can be used for tasks such as text generation, summarization, translation, classification, and more.\n",
    "\n",
    "Developers can also fine-tune these models on custom datasets or even build new models from scratch using the tools provided by Hugging Face. A key component of the platform is the Transformers library, which we used in this project. It provides seamless integration with popular deep learning frameworks like PyTorch and TensorFlow, making it easier to experiment and scale models across different environments.\n",
    "\n",
    "In addition to models, Hugging Face hosts datasets such as CoNLL2003.\n",
    "\n",
    "## SeqEval\n",
    "Seqeval is a Python library designed for evaluating sequence labeling tasks, such as Named Entity Recognition (NER), Part-of-Speech (POS) tagging, and chunking. It provides a simple and efficient way to compute standard evaluation metrics, including precision, recall, and F1-score, specifically tailored for structured prediction tasks where labels follow formats like IOB/IOB2. We adopt this library to evaluate our results and compare the various methods.\n",
    "\n",
    "## Ollama\n",
    "The ollama library provides a Python interface to interact with large language models (LLMs) running locally via the Ollama server. It allows users to send prompts, receive model-generated responses, and manage inference workflows directly from Python code. This makes it easy to integrate advanced generative AI capabilities into data analysis pipelines, research experiments, or application development, all while keeping computation on the local machine.\n",
    "\n",
    "## SpaCy\n",
    "The SpaCy library is an open-source software library for advanced natural language processing (NLP), written in Python and Cython. Unlike libraries such as NLTK, which are often used for teaching and research, spaCy is designed specifically for production use, offering fast and robust tools for tasks like tokenization, part-of-speech tagging, dependency parsing, text categorization, and named entity recognition (NER).\n",
    "\n",
    "spaCy supports deep learning workflows and can integrate with popular machine learning libraries such as TensorFlow and PyTorch via its own backend, Thinc. It provides prebuilt neural network models for 23 languages and supports tokenization for over 65 languages, making it suitable for both multilingual applications and custom model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7e6443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seqeval in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from seqeval) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-generativeai in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (2.25.0rc1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (2.169.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (2.40.0)\n",
      "Requirement already satisfied: protobuf in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (2.11.1)\n",
      "Requirement already satisfied: tqdm in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/francescostella/anaconda3/envs/nlp/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-genai\n",
    "%pip install seqeval\n",
    "%pip install google-generativeai\n",
    "%pip install ipywidgets --upgrade\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ea74f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (2.11.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic) (0.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets[all] in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from datasets[all]) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from datasets[all]) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (0.31.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from datasets[all]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from datasets[all]) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (3.11.18)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets[all]) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from requests>=2.32.2->datasets[all]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from requests>=2.32.2->datasets[all]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from requests>=2.32.2->datasets[all]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from requests>=2.32.2->datasets[all]) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from tqdm>=4.66.3->datasets[all]) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets[all]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pandas->datasets[all]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pandas->datasets[all]) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[all]) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets[all]) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: datasets 3.6.0 does not provide the extra 'all'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (0.4.8)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from ollama) (2.11.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.4)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (0.15.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (2.11.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<8.2,>=8.0.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucal\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lucal\\.conda\\envs\\insetti\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 2.6/12.8 MB 54.5 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 77.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 12.3/12.8 MB 110.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 93.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 65.5 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "WARNING: Skipping c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\scipy-1.13.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic\n",
    "!pip install datasets[all]\n",
    "!pip install pandas\n",
    "!pip install ollama\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425123a",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "For the development and evaluation of the prompts in this project, we used two different large language models: Gemma 3 (27B) and DeepSeek.\n",
    "\n",
    "## Gemma 3 (27b)\n",
    "\n",
    "We chose Gemma 3 because it is a recently released model by Google, offering several notable advantages:\n",
    "\n",
    "* Computational efficiency: Gemma 3 is a relatively lightweight model that achieves reasonable performance compared to state-of-the-art (SOTA) models like Gemini 2.5 Pro, which has over ten times more parameters.\n",
    "* API limits: Unlike many other models with free-tier APIs, Gemma 3 allows for a higher number of requests per day, making it more suitable for iterative development and testing.\n",
    "\n",
    "However, these advantages come with a significant trade-off:\n",
    "\n",
    "* Lower performance: In our tests, Gemma 3 underperformed compared to more advanced models. When evaluated against Gemini 2.0 Flash, we observed a performance gap of up to 20% in F1-score. Despite this, using higher-performing models was impractical due to API rate limitations, which would have required a considerable amount of additonal time to complete equivalent testing. \n",
    "\n",
    "The lower accuracy of Gemma 3 also influenced our implementation: model outputs required additional validation and post-processing. In some cases, responses did not adhere to the expected output format, necessitating extra checks and error handling in our code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613880d",
   "metadata": {},
   "source": [
    "## DeepSeek-R1 (distilled)\n",
    "In this section, we show and discuss our implementation on the DeepSeek-R1 model (distilled).\n",
    "\n",
    "### How to run DeepSeek-R1 locally\n",
    "Go to https://ollama.com, download and install ollama.\n",
    "Then, search for DeepSeek-R1's available models: https://ollama.com/library/deepseek-r1.\n",
    "Click on a model you wish to download and copy the command to run in the terminal (for instance: ollama run deepseek-r1:14b).\n",
    "\n",
    "\n",
    "### Model selection\n",
    "Our choice for the model was based on two factors: time consumption and performance.\n",
    "We decided to use `deepseek-r1:14b` because it generated tokens relatively fast while still performing almost as good as gemma-3-27b-it, a model we used previously which had acceptable performance.\n",
    "Trying to run bigger models such as deepseek-r1:32b was not feasible due to the very long token generation times.\n",
    "The increase in performance compared to deepseek-r1:14b was also very minimal, which led us to try even smaller models, such as deepseek-r1:7b and deepseek-r1:8b, which performed much worse instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87739fc",
   "metadata": {},
   "source": [
    "## **Implemented methods**\n",
    "In this section, we list and describe the methods we implemented using deepseek-r1:14b. Each prompt corresponds to a specific approach, and the results for each method are saved in a CSV file identified by the method's acronym.\n",
    "\n",
    "### - Word-level named entity reflection (WLNER)\n",
    "\n",
    "In this method, we add to the vanilla prompt another instruction which asks the model to generate a short summary for each word in the sentence. The summary had to be very short (around ten words) and is supposed to give an explanation, motivating the reason why a certain word can or cannot be a potential candidate to be classified as a NER tag.\n",
    "\n",
    "This approach explicitly leverages the **chain of thought** capability of large language models: by prompting the model to reflect and reason about each token individually, it is encouraged to articulate its decision-making process step by step. This not only helps the model to make more informed tagging decisions, but also provides interpretability, as the generated summaries reveal the rationale behind each prediction.\n",
    "\n",
    "However, this method performed slightly worse compared to the baseline reported in the reference paper.\n",
    "\n",
    ">This method was designed and developed by us specifically for this project.\n",
    "\n",
    "### - Multi-turn adaptive refinement (MTAR)\n",
    "\n",
    "In this method we asked the model to name the potential candidate words to be classified as NER tags. The model had to give an explanation for every word it believed to be a candidate NER tag, and then give the results in the correct format.\n",
    "\n",
    "Similarly to the previously mentioned method, this approach explicitly leverages the **chain of thought** capabilities of large language models. By prompting the model to reason step by step about which words are likely entities and to justify its choices, we encourage a more structured and interpretable decision-making process. This not only helps the model focus on the most relevant tokens, but also reduces the overall size of the output text generated, since the prompt specifies to just list the candidate NER tags and their explanations.\n",
    "\n",
    "This method performed slightly better compared to the baseline counterpart.\n",
    "\n",
    ">This method was designed and developed by us specifically for this project.\n",
    "\n",
    "### - Dependency-based entity validation (DBEV)\n",
    "In this method we added the dependency tree in the prompt, obtained by using spaCy (the dependency tree was not part of the dataset).\n",
    "\n",
    "The motivation behind this approach was to provide the model with additional syntactic information about the relationships between words in the sentence. By including the dependency tree, the model could potentially leverage the grammatical structure to better identify entities, especially in complex sentences where context and word dependencies play a crucial role.\n",
    "\n",
    "To implement this, we used spaCy to generate the dependency tree for each sentence, representing the syntactic relations in a structured format. This tree was then inserted into the prompt alongside the tokens to be tagged. The expectation was that the model, with access to this extra layer of linguistic information, would be able to make more informed tagging decisions, particularly in cases where surface-level cues were insufficient.\n",
    "\n",
    "However, in our experiments, we observed that the F1 score associated to this method was slightly worse.\n",
    "\n",
    "It is also important to note that the dependency trees were not originally part of the dataset and had to be computed using spaCy. This introduces a potential source of error, as the quality of the dependency parsing depends on the accuracy of spaCy's model. If the dataset had included gold-standard dependency trees, or if the dependency information had been annotated and curated specifically for the NER task, the results could have been better and the model might have been able to exploit this information more effectively.\n",
    "\n",
    ">This method was already used in the reference paper.\n",
    "\n",
    "### - POS-guided named entity recognition (POSGNER)\n",
    "In this method we added the POS tags for every token of the sentence, which are part of the dataset.\n",
    "\n",
    "The main idea behind this approach is to provide the model with explicit information about the grammatical role of each token in the sentence. Part-of-speech (POS) tags indicate whether a word is a noun, verb, adjective, proper noun, etc., and can be very helpful for named entity recognition because certain entity types are strongly associated with specific POS tags (for example, proper nouns are often persons, organizations, or locations).\n",
    "\n",
    "By including the POS tags in the prompt, we aimed to help the model disambiguate cases where the token alone might not be sufficient to determine the correct entity type. For instance, the word \"Apple\" could refer to a fruit (common noun) or a company (proper noun), and the POS tag can provide a useful clue for the model to make the right choice.\n",
    "\n",
    "In practice, we formatted the prompt so that the model received both the list of tokens and the corresponding POS tags in order. This additional information allowed the model to make more informed predictions, especially in sentences with ambiguous or rare words. Our experiments showed that this method generally improved the F1 score compared to the vanilla approach, confirming the usefulness of syntactic information for NER tasks.\n",
    "\n",
    "The performance scores indicate that this method was better than the baseline method implemented in the reference paper.\n",
    "\n",
    ">This method was already used in the reference paper.\n",
    "\n",
    "### - POS-dependency hybrid NER (POSDHNER)\n",
    "In this method we added to the prompt both the POS tags and the dependency tree.\n",
    "\n",
    "The rationale behind this approach is to combine two complementary sources of linguistic information: the part-of-speech (POS) tags, which indicate the grammatical role of each token, and the dependency tree, which describes the syntactic relationships between words in the sentence. By providing both types of annotations, we aimed to give the model a richer context for making NER predictions, especially in cases where either POS or dependency information alone might not be sufficient.\n",
    "\n",
    "In practice, the prompt was structured to include the list of tokens, their corresponding POS tags, and the full dependency tree (as computed by spaCy) for each sentence. This allowed the model to consider not only the type of each word but also how words are connected and which tokens are likely to form multi-word entities based on their syntactic structure.\n",
    "\n",
    "However, our experiments showed that the performance was close to the dependency-based entity validation method. Additionally, as with the dependency-based method, the quality of the dependency tree depends on the accuracy of spaCy's parser. If gold-standard dependency annotations had been available in the dataset, the results might have been better and the model could have leveraged this information more effectively.\n",
    "\n",
    ">This method was designed and developed by us specifically for this project.\n",
    "\n",
    "### - Example-driven POS NER (EDPOSNER)\n",
    "In this method we added the POS tags for every token of the sentence. We also added three complete examples, which consisted of the sentence tokens, POS tags and NER tags associated to such tokens. Thus this can be considered as a **few-shot learning** method.\n",
    "\n",
    "The main motivation for this approach was to provide the model with concrete, context-rich demonstrations of the NER task, making it easier for the model to generalize the tagging strategy to new sentences. By including three full examples in the prompt—each showing the tokens, their corresponding POS tags, and the correct NER tags—the model could observe how the tagging should be performed in practice, even for more complex or ambiguous cases.\n",
    "\n",
    "In our experiments, this method generally led to similar performance compared to the original prompt without examples.\n",
    "\n",
    ">This method was designed and developed by us specifically for this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c79ecb",
   "metadata": {},
   "source": [
    "### Evaluation Without BIO Tag Distinction\n",
    "\n",
    "In addition to the standard evaluation using the full BIO tagging scheme (where each entity is labeled as either Beginning (B), Inside (I), or Outside (O)), we also conducted experiments by removing the distinction between B- and I- tags. In this alternative evaluation, entity types are considered without regard to whether a token is at the beginning or inside of an entity span. For example, both `B-PER` and `I-PER` are mapped to a single `PER` category.\n",
    "\n",
    "This approach allows us to consider a prediction as correct even if the model predicts a `B` tag instead of an `I` tag (or vice versa), as long as the entity type itself is correct. The motivation behind this evaluation is to focus on the model's ability to recognize the correct entity type, regardless of its position within the entity span. This can be particularly useful for assessing the robustness of the model in scenarios where the precise span boundaries are less critical than the correct identification of entity types.\n",
    "\n",
    "To implement this, we mapped all `B-` and `I-` tags of the same entity type to a single label. The evaluation metrics were then computed on these simplified labels, providing an additional perspective on the model's performance.\n",
    "\n",
    "The csvs obtained by ignoring the BIO tagging end with **NOBIO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2186b83",
   "metadata": {},
   "source": [
    "### Model's response parsers\n",
    "\n",
    "Here we list the functions for parsing and storing the model's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0377c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def parse_response(tokens : list, response_labels : list, true_labels : list) -> list: \n",
    "    '''\n",
    "    Store the response in a list of lists where the first element is the token, the second element \n",
    "    is the predicted label and the third is the true label\n",
    "    '''\n",
    "    response_labels = response_labels.split(\":\")\n",
    "    response_labels = response_labels[1].strip('\\n').split(',')\n",
    "    if (len(response_labels) != len(tokens)):\n",
    "        if (len(response_labels) > len(tokens)):\n",
    "            response_labels = response_labels[:len(tokens)]\n",
    "        if (len(response_labels) < len(tokens)):\n",
    "            response_labels = response_labels + ['0'] * (len(tokens) - len(response_labels))\n",
    "\n",
    "    temp = []\n",
    "    for i in range(len(tokens)):\n",
    "        pred_label = int(response_labels[i].strip())\n",
    "        if(pred_label < 0 or pred_label > 8):\n",
    "            print(f\"Token: {tokens[i]}, Predicted Label: {pred_label}, True Label: {true_labels[i]}\")\n",
    "        #assert (pred_label >= 0 and pred_label <= 8), \"Predicted label is out of range\"\n",
    "        temp.append([tokens[i], pred_label, true_labels[i]])\n",
    "\n",
    "    return temp\n",
    "\n",
    "def save_to_csv_vanilla(tokens : list, pred_labels : list, true_labels : list, filename : str) -> None:\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    # Write header only if the file didn't exist before\n",
    "    if not file_exists:\n",
    "        with open(filename, 'a', newline='') as csvfile:\n",
    "            header = ['token', 'pred', 'true']\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(header)\n",
    "    if (len(pred_labels) == 0 and len(true_labels) == 0):\n",
    "        return\n",
    "    data = [[tokens[i], pred_labels[i], true_labels[i]] for i in range(len(tokens)) if pred_labels[i] != 0 or true_labels[i] != 0]\n",
    "    # Remove duplicates\n",
    "    # Open the file in append mode and write data to analysis purpose\n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "begin_tags = {1,3,5,7}\n",
    "\n",
    "def parse_response_no_bio(tokens : list, response_labels : list, true_labels : list) -> list: \n",
    "    '''\n",
    "    Store the response in a list of lists where the first element is the token, the second element \n",
    "    is the predicted label and the third is the true label\n",
    "    '''\n",
    "    response_labels = response_labels.split(\":\")\n",
    "    response_labels = response_labels[1].strip('\\n').split(',')\n",
    "    if (len(response_labels) != len(tokens)):\n",
    "        if (len(response_labels) > len(tokens)):\n",
    "            response_labels = response_labels[:len(tokens)]\n",
    "        if (len(response_labels) < len(tokens)):\n",
    "            response_labels = response_labels + ['0'] * (len(tokens) - len(response_labels))\n",
    "\n",
    "    temp = []\n",
    "    for i in range(len(tokens)):\n",
    "        if i > 0 and temp[i-1][1] in begin_tags and int(response_labels[i].strip()) in begin_tags:\n",
    "            # If the previous token is a begin tag and this is not '0', we assume it's a continuation\n",
    "            pred_label = int(response_labels[i].strip()) + 1\n",
    "        elif i > 0 and int(response_labels[i].strip()) in begin_tags and (temp[i-1][1] - 1) == int(response_labels[i].strip()):\n",
    "            # if previous token is an inside token and the current is in the same category, we assume it's a continuation\n",
    "            pred_label = int(response_labels[i].strip()) + 1\n",
    "        else:\n",
    "            # Otherwise, we take the label as is\n",
    "            pred_label = int(response_labels[i].strip())\n",
    "        if(pred_label < 0 or pred_label > 8):\n",
    "            print(f\"Token: {tokens[i]}, Predicted Label: {pred_label}, True Label: {true_labels[i]}\")\n",
    "        #assert (pred_label >= 0 and pred_label <= 8), \"Predicted label is out of range\"\n",
    "        temp.append([tokens[i], pred_label, true_labels[i]])\n",
    "\n",
    "    return temp\n",
    "\n",
    "\n",
    "# Take predicted labels and for each token save the label in a list to be used for voting\n",
    "def store_predicted_labels(pred_labels : list, votes : list) -> None:\n",
    "    for i in range(len(pred_labels)):\n",
    "        votes[i].append(pred_labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e2353",
   "metadata": {},
   "source": [
    "### Training data sampling\n",
    "\n",
    "Here we sample the first 100 sentences from the training set using a fixed seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9648340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "{'id': '13835', 'tokens': ['RESERVES', '(', '$', 'MLN', ')', 'Jul', '+1,161', '+400.9', '+310.4', '-', '54,703.0'], 'pos_tags': [24, 4, 3, 22, 5, 22, 11, 11, 11, 8, 11], 'chunk_tags': [11, 0, 11, 12, 0, 11, 12, 12, 12, 12, 12], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "\n",
      "Sample 2:\n",
      "{'id': '6311', 'tokens': ['7.', 'Sebastian', 'Lindholm', '(', 'Finland', ')', 'Ford', 'Escort', '5:17'], 'pos_tags': [22, 22, 22, 4, 22, 5, 22, 22, 11], 'chunk_tags': [11, 12, 12, 0, 11, 0, 11, 12, 12], 'ner_tags': [0, 1, 2, 0, 5, 0, 7, 8, 0]}\n",
      "\n",
      "\n",
      "Sample 3:\n",
      "{'id': '12418', 'tokens': ['7', '-', 'Chris', 'Walker', '(', 'England', ')', 'beat', 'Amr', 'Shabana', '(', 'Egypt', ')', '15-13', '15-10', '15-6'], 'pos_tags': [11, 8, 22, 22, 4, 22, 5, 37, 22, 22, 4, 22, 5, 11, 16, 11], 'chunk_tags': [11, 12, 12, 12, 0, 11, 0, 21, 11, 12, 0, 11, 0, 11, 12, 12], 'ner_tags': [0, 0, 1, 2, 0, 5, 0, 0, 1, 2, 0, 5, 0, 0, 0, 0]}\n",
      "\n",
      "\n",
      "Sample 4:\n",
      "{'id': '6890', 'tokens': ['OB', '2', 'Lotte', '1'], 'pos_tags': [22, 11, 22, 11], 'chunk_tags': [11, 12, 12, 12], 'ner_tags': [3, 0, 3, 0]}\n",
      "\n",
      "\n",
      "Sample 5:\n",
      "{'id': '663', 'tokens': ['5/8', '-', 'Meluawati', '(', 'Indonesia', ')', 'beat', 'Chan', 'Chia', 'Fong', '(', 'Malaysia', ')', '11-6'], 'pos_tags': [11, 8, 14, 4, 22, 5, 37, 22, 22, 22, 4, 22, 5, 11], 'chunk_tags': [11, 12, 0, 0, 0, 0, 21, 11, 12, 12, 0, 11, 0, 11], 'ner_tags': [0, 0, 1, 0, 5, 0, 0, 1, 2, 2, 0, 5, 0, 0]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# Sample 100 random elements from the test set\n",
    "sampled_train_data = random.sample(list(train_data), 100)\n",
    "\n",
    "# Print the first few samples to verify\n",
    "for i, sample in enumerate(sampled_train_data[:5]):  # Display the first 5 samples\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(sample)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f689085",
   "metadata": {},
   "source": [
    "### Dependency tree computation\n",
    "\n",
    "Here we report the code for computing the dependency trees for the training data usign spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0df39eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\asyncio\\base_events.py\", line 639, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\asyncio\\base_events.py\", line 1985, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lucal\\AppData\\Local\\Temp\\ipykernel_2484\\977494362.py\", line 1, in <module>\n",
      "    import spacy\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"c:\\Users\\lucal\\.conda\\envs\\insetti\\Lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "C:\\Users\\lucal\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'RESERVES', 'dep': 'nsubj', 'head': '+1,161', 'pos': 'NOUN', 'index': 0, 'head_index': 6}, {'text': '(', 'dep': 'punct', 'head': 'RESERVES', 'pos': 'PUNCT', 'index': 1, 'head_index': 0}, {'text': '$', 'dep': 'nmod', 'head': 'MLN', 'pos': 'SYM', 'index': 2, 'head_index': 3}, {'text': 'MLN', 'dep': 'appos', 'head': 'RESERVES', 'pos': 'X', 'index': 3, 'head_index': 0}, {'text': ')', 'dep': 'punct', 'head': 'MLN', 'pos': 'PUNCT', 'index': 4, 'head_index': 3}, {'text': 'Jul', 'dep': 'appos', 'head': 'RESERVES', 'pos': 'PROPN', 'index': 5, 'head_index': 0}, {'text': '+1,161', 'dep': 'ROOT', 'head': '+1,161', 'pos': 'VERB', 'index': 6, 'head_index': 6}, {'text': '+400.9', 'dep': 'advmod', 'head': '+1,161', 'pos': 'ADV', 'index': 7, 'head_index': 6}, {'text': '+310.4', 'dep': 'dep', 'head': '+400.9', 'pos': 'NUM', 'index': 8, 'head_index': 7}, {'text': '-', 'dep': 'punct', 'head': '54,703.0', 'pos': 'PUNCT', 'index': 9, 'head_index': 10}, {'text': '54,703.0', 'dep': 'dobj', 'head': '+1,161', 'pos': 'NOUN', 'index': 10, 'head_index': 6}]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "dependency_trees = []\n",
    "\n",
    "for sample in sampled_train_data:\n",
    "    tokens = sample[\"tokens\"]\n",
    "    sentence = \" \".join(tokens)\n",
    "    doc = nlp(sentence)\n",
    "    tree = [\n",
    "        {\n",
    "            \"text\": token.text,\n",
    "            \"dep\": token.dep_,\n",
    "            \"head\": token.head.text,\n",
    "            \"pos\": token.pos_,\n",
    "            \"index\": token.i,\n",
    "            \"head_index\": token.head.i\n",
    "        }\n",
    "        for token in doc\n",
    "    ]\n",
    "    dependency_trees.append(tree)\n",
    "\n",
    "# Link the two lists\n",
    "for i, sample in enumerate(sampled_train_data):\n",
    "    sample['dependency_tree'] = dependency_trees[i]\n",
    "\n",
    "# Now each sample has the tree inside\n",
    "print(sampled_train_data[0]['dependency_tree'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f014ccb",
   "metadata": {},
   "source": [
    "### Clean response function\n",
    "\n",
    "This function is used to format properly the response coming from a deepseek model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b679457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from ollama import Client\n",
    "\n",
    "\n",
    "def clean_response(text):\n",
    "    \"\"\"Cleans the model's output to extract only the numbers.\"\"\"\n",
    "    # Remove <think>...</think> blocks\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Look for the pattern 'ner_tags: 0, 1, 2, ...'\n",
    "    match = re.search(r'ner_tags\\s*:\\s*([0-9,\\s]+)', cleaned)\n",
    "    if match:\n",
    "        number_str = match.group(1)\n",
    "    else:\n",
    "        # If 'ner_tags:' is not found, but there are still numbers, extract them all\n",
    "        number_str = cleaned\n",
    "\n",
    "    # Extract all integers as strings\n",
    "    number_list = re.findall(r'\\d+', number_str)\n",
    "    return number_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5d1d1",
   "metadata": {},
   "source": [
    "### Format example function\n",
    "\n",
    "This function is used for the few-shot prompts, giving them a formatted example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a733e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(ex):\n",
    "    return f\"\"\"Tokens: {ex['tokens']}\n",
    "POS tags: {ex['pos_tags']}\n",
    "NER tags: {ex['ner_tags']}\"\"\"\n",
    "\n",
    "# Using 3 random examples in the prompt (different from the ones used in the training)\n",
    "example1 = train_data[11000]\n",
    "example2 = train_data[12000]\n",
    "example3 = train_data[13000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059385e",
   "metadata": {},
   "source": [
    "## Best prompt (POS-guided named entity recognition)\n",
    "\n",
    "Here we report the best prompt found using deepseek-r1:14b and the code used to generate the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client\n",
    "client = Client()\n",
    "\n",
    "for j in range(len(sampled_train_data)):\n",
    "    tokens = sampled_train_data[j]['tokens']\n",
    "    pos_tags = sampled_train_data[j]['pos_tags']\n",
    "    true_labels = sampled_train_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_train_ds/vanilla_train_100_ds_14b_POSGNER.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f30e37",
   "metadata": {},
   "source": [
    "### Using the same model without the BIO tagging\n",
    "\n",
    "Here we present the code used for the same prompt without using the BIO tagging.\n",
    "For this instance, the F1 score obtained using the nobio format was worse compared to his regular counterpart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client\n",
    "client = Client()\n",
    "\n",
    "for j in range(len(sampled_train_data)):\n",
    "    tokens = sampled_train_data[j]['tokens']\n",
    "    pos_tags = sampled_train_data[j]['pos_tags']\n",
    "    true_labels = sampled_train_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'B-ORG': 3, 'B-LOC': 5, 'B-MISC': 7}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_train_ds/vanilla_train_100_ds_14b_POSGNER_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014ad2d",
   "metadata": {},
   "source": [
    "### Removal of Rows with Invalid Prediction Labels\n",
    "To ensure the correctness of our evaluation, we removed all rows from the CSV files where the prediction label (pred) was not an integer between 0 and 8 (inclusive). Specifically, any row with a pred value outside this range, or with a non-integer value, was discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "input_folder = 'data100_train_ds'\n",
    "output_folder = 'data100_ds_corrected'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        rows = []\n",
    "        with open(input_path, newline='', encoding='utf-8') as infile:\n",
    "            reader = csv.DictReader(infile)\n",
    "            fieldnames = reader.fieldnames\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    pred = int(row['pred'])\n",
    "                    if 0 <= pred <= 8:\n",
    "                        row['pred'] = str(pred)\n",
    "                        rows.append(row)\n",
    "                    # Otherwise, the row is discarded\n",
    "                except ValueError:\n",
    "                    # Row is discarded if pred cannot be converted to int\n",
    "                    continue\n",
    "\n",
    "        with open(output_path, 'w', newline='', encoding='utf-8') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c07507",
   "metadata": {},
   "source": [
    "### Confrontation between the prompts\n",
    "\n",
    "Here we report the F1 scores obtained with the various prompts tested on the training data, organized from best to worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b75b07d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_train_100_ds_14b_ADVANCEDPOS_NOBIO.csv: F1 Score = 0.6074498567335244\n",
      "vanilla_train_100_ds_14b_POSGNER.csv: F1 Score = 0.5649717514124294\n",
      "vanilla_train_100_ds_14b_ADVANCED_NOBIO.csv: F1 Score = 0.5630498533724341\n",
      "vanilla_train_100_ds_14b_EDPOSNER_NOBIO.csv: F1 Score = 0.5574712643678161\n",
      "vanilla_train_100_ds_14b_NOBIO.csv: F1 Score = 0.5531914893617021\n",
      "vanilla_train_100_ds_14b_MTAR_NOBIO.csv: F1 Score = 0.5406824146981627\n",
      "vanilla_train_100_ds_14b_POSGNER_NOBIO.csv: F1 Score = 0.516795865633075\n",
      "vanilla_train_100_ds_14b_MTAR.csv: F1 Score = 0.5111111111111112\n",
      "vanilla_train_100_ds_14b.csv: F1 Score = 0.5013774104683195\n",
      "vanilla_train_100_ds_14b_EDPOSNER.csv: F1 Score = 0.49853372434017595\n",
      "vanilla_train_100_ds_14b_POSDHNER_NOBIO.csv: F1 Score = 0.4876847290640394\n",
      "vanilla_train_100_ds_14b_WLNER_NOBIO.csv: F1 Score = 0.48292682926829267\n",
      "vanilla_train_100_ds_14b_WLNER.csv: F1 Score = 0.47916666666666663\n",
      "vanilla_train_100_ds_14b_DBEV_NOBIO.csv: F1 Score = 0.4766839378238342\n",
      "vanilla_train_100_ds_14b_POSDHNER.csv: F1 Score = 0.46334310850439886\n",
      "vanilla_train_100_ds_14b_DBEV.csv: F1 Score = 0.42424242424242425\n",
      "\n",
      "Best file: vanilla_train_100_ds_14b_ADVANCEDPOS_NOBIO.csv\n",
      "Best F1 Score: 0.6074498567335244\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "label_mapping = {\n",
    "    0: 'O',\n",
    "    1: 'B-PER',\n",
    "    2: 'I-PER',\n",
    "    3: 'B-ORG',\n",
    "    4: 'I-ORG',\n",
    "    5: 'B-LOC',\n",
    "    6: 'I-LOC',\n",
    "    7: 'B-MISC',\n",
    "    8: 'I-MISC'\n",
    "}\n",
    "\n",
    "folder = 'data100_ds_corrected'\n",
    "best_f1 = -1\n",
    "best_file = None\n",
    "results = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        true_seqs = []\n",
    "        pred_seqs = []\n",
    "        current_true = []\n",
    "        current_pred = []\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        with open(filepath, newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    true_label = label_mapping[int(row['true'])]\n",
    "                    pred_label = label_mapping[int(row['pred'])]\n",
    "                    current_true.append(true_label)\n",
    "                    current_pred.append(pred_label)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if current_true and current_pred:\n",
    "                true_seqs.append(current_true)\n",
    "                pred_seqs.append(current_pred)\n",
    "        if true_seqs and pred_seqs:\n",
    "            f1 = f1_score(true_seqs, pred_seqs)\n",
    "            results.append((filename, f1))\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_file = filename\n",
    "\n",
    "# Prints the results sorted by F1 score\n",
    "for fname, f1 in sorted(results, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{fname}: F1 Score = {f1}\")\n",
    "\n",
    "print(\"\\nBest file:\", best_file)\n",
    "print(\"Best F1 Score:\", best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e870c7",
   "metadata": {},
   "source": [
    "## **Confrontation between our models, prompt switching and prompt mixing**\n",
    "After evaluating the various prompts for our models, we chose to focus on those approaches that provided the highest F1 scores.\n",
    "The next step consisted in applying the best-performing prompt from one model to the other model. In this way, we could directly compare whether the improvements were due to the prompt itself or to the specific model architecture.\n",
    "\n",
    "In particular, we took the prompt that gave the best results with the first model and used it as input for the second model, and vice versa. This allowed us to assess the transferability and general effectiveness of each prompt, independently of the model for which it was originally designed.\n",
    "\n",
    "In the end, we also experimented with combining the two best prompts, integrating their most effective elements into a single hybrid prompt. This \"prompt mixing\" approach aimed to leverage the strengths of both strategies, further improving the overall performance and robustness of our NER system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f918d",
   "metadata": {},
   "source": [
    "We now present the results obtained by running deepseek-r1:14b with the best prompt originally designed for Gemma 3-27b-it. The F1-score achieved with this approach is very close to the one obtained using the POS-guided named entity recognition prompt, suggesting that both prompts are effective for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c434997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client\n",
    "client = Client()\n",
    "\n",
    "for j in range(len(sampled_train_data)):\n",
    "    tokens = sampled_train_data[j]['tokens']\n",
    "    pos_tags = sampled_train_data[j]['pos_tags']\n",
    "    true_labels = sampled_train_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are an expert in Named Entity Recognition (NER). Your task is to assign an entity tag ID to each token in the sentence using the strict schema below.\n",
    "\n",
    "    NER Tag IDs:\n",
    "    - 0 = O → Not an entity  \n",
    "    - 1 = PERSON → Real names, personal titles (e.g., \"Barack\", \"Dr.\", \"Angela\")  \n",
    "    - 3 = ORGANIZATION → Companies, institutions, teams, agencies (e.g., \"Google\", \"United Nations\", \"Lakers\", \"Juventus\")  \n",
    "    - 5 = LOCATION → Cities, countries, natural landmarks, buildings (e.g., \"Paris\", \"Mount Everest\", \"Empire State Building\")  \n",
    "    - 7 = MISCELLANEOUS → Nationalities, languages, events, products, titles of works (e.g., \"Italian\", \"Olympics\", \"iPhone\", \"French\", \"The Matrix\")\n",
    "\n",
    "    ---\n",
    "\n",
    "    Rules:\n",
    "    - Use only contextual evidence to determine entity types.\n",
    "    - If the token does not clearly match a defined type, assign `0 (O)`.\n",
    "    - Please do not assign tags based on assumptions or incomplete context.\n",
    "    - Please be as precise as possible\n",
    "\n",
    "    ---\n",
    "\n",
    "    Now tag the sentence below:\n",
    "    Sentence: {tokens}  \n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    Your answer MUST follow this format:  \n",
    "    ner_tags: 0, 1, 0, 5, 5, 0  \n",
    "    (Must return exactly {len(tokens)} tag IDs in order, no extra text.)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_train_ds/vanilla_train_100_ds_14b_ADVANCED_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c97d60",
   "metadata": {},
   "source": [
    "We now present the results obtained by running the model with a hybrid prompt that combines the best elements from the Gemma 3-27b-it prompt and the POS-guided named entity recognition approach. In this prompt, the model is provided with both detailed definitions for each entity type and the part-of-speech (POS) tags for every token in the sentence. The instructions explicitly require the model to use only contextual evidence, avoid making assumptions, and to be as precise as possible when assigning entity tags.\n",
    "\n",
    "By integrating both the explicit entity schema and the syntactic information from POS tags, this prompt aims to maximize the model's ability to accurately identify and classify entities. The F1-score achieved with this combined prompt is even higher than those obtained with either the Gemma 3-27b-it prompt or the POS-guided prompt alone. This improvement suggests that the two strategies are complementary: the detailed entity definitions help clarify the categories, while the POS tags provide valuable grammatical context for disambiguating entity types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d6e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client\n",
    "client = Client()\n",
    "\n",
    "for j in range(len(sampled_train_data)):\n",
    "    tokens = sampled_train_data[j]['tokens']\n",
    "    pos_tags = sampled_train_data[j]['pos_tags']\n",
    "    true_labels = sampled_train_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are an expert in Named Entity Recognition (NER). Your task is to assign an entity tag ID to each token in the sentence using the strict schema below.\n",
    "\n",
    "    NER Tag IDs:\n",
    "    - 0 = O → Not an entity  \n",
    "    - 1 = PERSON → Real names, personal titles (e.g., \"Barack\", \"Dr.\", \"Angela\")  \n",
    "    - 3 = ORGANIZATION → Companies, institutions, teams, agencies (e.g., \"Google\", \"United Nations\", \"Lakers\", \"Juventus\")  \n",
    "    - 5 = LOCATION → Cities, countries, natural landmarks, buildings (e.g., \"Paris\", \"Mount Everest\", \"Empire State Building\")  \n",
    "    - 7 = MISCELLANEOUS → Nationalities, languages, events, products, titles of works (e.g., \"Italian\", \"Olympics\", \"iPhone\", \"French\", \"The Matrix\")\n",
    "\n",
    "    ---\n",
    "\n",
    "    Rules:\n",
    "    - Use only contextual evidence to determine entity types.\n",
    "    - If the token does not clearly match a defined type, assign `0 (O)`.\n",
    "    - Please do not assign tags based on assumptions or incomplete context.\n",
    "    - Please be as precise as possible\n",
    "\n",
    "    ---\n",
    "\n",
    "    Now tag the sentence below:\n",
    "    Sentence: {tokens}  \n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "    \n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "\n",
    "    Your answer MUST follow this format:  \n",
    "    ner_tags: 0, 1, 0, 5, 5, 0  \n",
    "    (Must return exactly {len(tokens)} tag IDs in order, no extra text.)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_train_ds/vanilla_train_100_ds_14b_ADVANCEDPOS_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c118c",
   "metadata": {},
   "source": [
    "## Running the model on the test set\n",
    "\n",
    "In this section, we apply the best-performing prompt to the test set to evaluate the generalization ability of our models. This allows us to assess the final performance of each approach on unseen data and compare the results obtained during training with those on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b1c26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "# Sample 100 random elements from the test set\n",
    "sampled_test_data = random.sample(list(test_data), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e3f39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Sentence 0\n",
      "Tokens:     ['\"', 'The', 'recent', 'level', 'of', 'the', 'yen', 'exchange', 'rate', 'has', 'been', 'stable', ',', 'and', 'it', 'does', 'not', 'appear', 'to', 'be', 'moving', 'towards', 'a', 'further', 'depreciation', 'of', 'the', 'yen', 'immediately', ',', 'so', 'import', 'prices', 'are', 'likely', 'to', 'stabilise', 'at', 'current', 'levels', ',', '\"', 'Matsushita', 'said', 'in', 'an', 'interview', 'with', 'the', 'Nihon', 'Keizai', 'Shimbun', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0]\n",
      "---\n",
      "[✓] Sentence 1\n",
      "Tokens:     ['Blackpool', '0', 'Hednesford', '1']\n",
      "Predicted:  [5, 0, 5, 0]\n",
      "True:       [3, 0, 3, 0]\n",
      "---\n",
      "[✓] Sentence 2\n",
      "Tokens:     ['Wheat', '387.4', '4677.8', '4553.6', '55.2', '1039.7', '846.1']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 3\n",
      "Tokens:     ['Ulker', 'Spor', '(', 'Turkey', ')', '9', '4', '5', '13']\n",
      "Predicted:  [1, 4, 0, 5, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 5, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 4\n",
      "Tokens:     ['He', 'said', 'at', 'one', 'point', 'during', 'a', 'press', 'conference', ':', '\"', 'I', 'have', 'seen', 'my', 'whip', '(', 'party', 'manager', ')', 'for', 'next', 'week', 'which', ',', 'of', 'course', ',', 'does', \"n't\", 'mean', 'very', 'much', 'to', 'me', 'now', '.', '\"']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 5\n",
      "Tokens:     ['Alexander', 'Bavykin', ',', 'deputy', 'legal', 'chief', 'at', 'Russia', \"'s\", 'foreign', 'ministry', ',', 'said', 'Moscow', 'had', 'yet', 'to', 'formulate', 'a', 'policy', 'on', 'copyright', 'in', 'cybersppace', '.']\n",
      "Predicted:  [1, 2, 0, 0, 0, 0, 0, 5, 0, 0, 3, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0]\n",
      "True:       [1, 2, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 6\n",
      "Tokens:     ['Turkey', 'says', 'Syria', 'sponsors', 'the', 'PKK', ',', 'fighting', 'for', 'Kurdish', 'self-rule', 'in', 'southeast', 'Turkey', '.']\n",
      "Predicted:  [5, 0, 5, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 5, 0]\n",
      "True:       [5, 0, 5, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 7\n",
      "Tokens:     ['--', 'U.S.', 'Municipal', 'Desk', ',', '212-859-1650']\n",
      "Predicted:  [0, 5, 4, 4, 0, 0]\n",
      "True:       [0, 3, 4, 4, 0, 0]\n",
      "---\n",
      "[✓] Sentence 8\n",
      "Tokens:     ['Hapoel', 'Beit', \"She'an\", '2', 'Hapoel', 'Beersheba', '1']\n",
      "Predicted:  [3, 0, 5, 0, 3, 6, 0]\n",
      "True:       [3, 4, 4, 0, 3, 4, 0]\n",
      "---\n",
      "[✓] Sentence 9\n",
      "Tokens:     ['Real', 'Madrid', \"'s\", 'Balkan', 'strike', 'force', 'of', 'Davor', 'Suker', 'and', 'Predrag', 'Mijatovic', 'shot', 'their', 'side', 'to', 'a', '2-0', 'win', 'over', 'Barcelona', 'in', 'Spain', \"'s\", 'old', 'firm', 'game', 'on', 'Saturday', '.']\n",
      "Predicted:  [3, 4, 0, 5, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 7, 0, 0, 0]\n",
      "True:       [3, 4, 0, 5, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 10\n",
      "Tokens:     ['\"', 'French', 'troops', 'may', 'only', 'take', 'part', 'in', 'maintaining', 'order', 'to', 'avoid', 'major', 'abuses', 'and', 'protect', 'foreign', 'communities', ',', '\"', 'he', 'said', '.']\n",
      "Predicted:  [0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 11\n",
      "Tokens:     ['Two', 'people', 'were', 'killed', 'when', 'an', 'executive', 'jet', 'en', 'route', 'to', 'Ireland', 'from', 'Michigan', 'crashed', 'on', 'approach', 'to', 'an', 'airport', 'in', 'Stephenville', ',', 'Newfoundland', ',', 'on', 'Friday', ',', 'authorities', 'said', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 7, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 12\n",
      "Tokens:     [\"'\", \"'\", 'In', 'January', 'or', 'February', ',', 'we', \"'ll\", 'have', 'some', 'very', 'close', 'contacts', 'with', 'Mexico', 'to', 'add', 'the', 'issue', 'of', 'services', 'and', 'advance', 'on', 'the', 'issue', 'of', 'investments', ',', \"'\", \"'\", 'Aninat', 'told', 'reporters', 'after', 'signing', 'a', 'free', 'trade', 'deal', 'with', 'Canada', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 13\n",
      "Tokens:     ['Name', ':', 'Svetlana', 'Gladishiva']\n",
      "Predicted:  [0, 0, 1, 2]\n",
      "True:       [0, 0, 1, 2]\n",
      "---\n",
      "[✓] Sentence 14\n",
      "Tokens:     ['\"', 'I', 'look', 'forward', 'to', 'continuing', 'our', 'good', 'relations', '...']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 15\n",
      "Tokens:     ['A', 'New', 'Mexico', 'high', 'school', 'football', 'player', 'who', 'used', 'razor-sharp', 'helmet', 'buckles', 'to', 'slash', 'opponents', 'and', 'a', 'referee', 'was', 'expelled', 'from', 'high', 'school', 'banned', 'Thursday', 'from', 'competition', 'for', 'one', 'year', '.']\n",
      "Predicted:  [0, 0, 0, 5, 0, 0, 0, 5, 2, 2, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 16\n",
      "Tokens:     ['Standings', '(', 'tabulate', 'under', 'played', ',', 'won', ',', 'drawn', ',', 'lost', ',', 'goals']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 17\n",
      "Tokens:     ['Santa', 'Fe', 'is', 'so', 'far', 'mum', 'on', 'the', 'more', 'than', '$', '2', 'billion', 'stock', 'swap', 'takeover', 'proposal', 'from', 'Newmont', ',', 'announced', 'Thursday', '.']\n",
      "Predicted:  [5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 18\n",
      "Tokens:     ['PSV', 'Eindhoven', '18', '13', '3', '2', '52', '14', '42']\n",
      "Predicted:  [3, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 19\n",
      "Tokens:     ['Ipswich', '0', 'Wolverhampton', '0']\n",
      "Predicted:  [5, 0, 5, 0]\n",
      "True:       [3, 0, 3, 0]\n",
      "---\n",
      "[✓] Sentence 20\n",
      "Tokens:     ['VANCOUVER', '14', '11', '1', '84', '83', '29']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 21\n",
      "Tokens:     ['Saturday', \"'s\", 'women', \"'s\", 'World', 'Cup', 'downhill', 'race', ':']\n",
      "Predicted:  [0, 0, 0, 0, 7, 8, 0, 7, 0]\n",
      "True:       [0, 0, 0, 0, 7, 8, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 22\n",
      "Tokens:     ['TORONTO', '6', '11', '.353', '10', '1/2']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 23\n",
      "Tokens:     ['LONDON', '1996-12-06']\n",
      "Predicted:  [5, 0]\n",
      "True:       [5, 0]\n",
      "---\n",
      "[✓] Sentence 24\n",
      "Tokens:     ['There', 'was', 'no', 'Bundesbank', 'intervention', '.']\n",
      "Predicted:  [0, 0, 0, 3, 0, 0]\n",
      "True:       [0, 0, 0, 3, 0, 0]\n",
      "---\n",
      "[✓] Sentence 25\n",
      "Tokens:     ['15,232']\n",
      "Predicted:  [0]\n",
      "True:       [0]\n",
      "---\n",
      "[✓] Sentence 26\n",
      "Tokens:     ['NEW', 'YORK', '1996-12-07']\n",
      "Predicted:  [5, 6, 0]\n",
      "True:       [5, 6, 0]\n",
      "---\n",
      "[✓] Sentence 27\n",
      "Tokens:     ['10=', 'Florence', 'Masnada', '(', 'France', ')', '51']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 5, 1, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 28\n",
      "Tokens:     ['Bayern', 'Munich', '16', '9', '6', '1', '26', '14', '33']\n",
      "Predicted:  [3, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 29\n",
      "Tokens:     ['The', 'freak', 'accident', 'occurred', 'in', 'Mafikeng', 'on', 'Thursday', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 5, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 5, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 30\n",
      "Tokens:     ['NEW', 'YORK', '1996-12-06']\n",
      "Predicted:  [5, 6, 0]\n",
      "True:       [5, 6, 0]\n",
      "---\n",
      "[✓] Sentence 31\n",
      "Tokens:     ['Southend', '22', '5', '9', '8', '23', '36', '24']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 32\n",
      "Tokens:     ['The', 'West', 'Indies', 'vice-captain', 'struggled', 'for', 'timing', 'during', 'his', '36-minute', 'stay', 'at', 'the', 'crease', 'before', 'chipping', 'a', 'ball', 'from', 'medium', 'pacer', 'Tom', 'Moody', 'straight', 'to', 'Shane', 'Warne', 'at', 'mid-wicket', '.']\n",
      "Predicted:  [0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0]\n",
      "True:       [0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 33\n",
      "Tokens:     ['Results', 'of', 'Northern', 'Ireland', 'premier']\n",
      "Predicted:  [0, 0, 0, 5, 8]\n",
      "True:       [0, 0, 5, 6, 0]\n",
      "---\n",
      "[✓] Sentence 34\n",
      "Tokens:     ['December', '25', ',', 'a', 'normal', 'working', 'day', 'in', 'Russia', ',', 'is', 'the', 'fifth', 'anniversary', 'of', 'Yeltsin', \"'s\", 'arrival', 'in', 'the', 'Kremlin', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 1, 0, 0, 0, 0, 5, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 35\n",
      "Tokens:     ['Salomon', \"'s\", 'bond', 'index', 'is', 'calculated', 'using', 'all', 'government', 'bonds', 'with', 'over', 'one', 'year', 'to', 'maturity', ',', 'weighted', 'for', 'market', 'capitalisation', '.']\n",
      "Predicted:  [0, 0, 7, 8, 0, 0, 0, 0, 3, 8, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 8, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 36\n",
      "Tokens:     ['China', \"'s\", 'tourist', 'spot', 'of', 'Guilin', 'in', 'the', 'southern', 'region', 'of', 'Guangxi', 'will', 'open', 'its', 'airport', 'to', 'foreign', 'aircraft', ',', 'the', 'Xinhua', 'news', 'agency', 'said', 'on', 'Friday', '.']\n",
      "Predicted:  [5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]\n",
      "True:       [5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 37\n",
      "Tokens:     ['Phoenix', '3', 'ST', 'LOUIS', '0']\n",
      "Predicted:  [5, 0, 5, 6, 0]\n",
      "True:       [3, 0, 3, 4, 0]\n",
      "---\n",
      "[✓] Sentence 38\n",
      "Tokens:     ['-', 'Gulf', 'of', 'Mexico', ':']\n",
      "Predicted:  [0, 5, 0, 5, 0]\n",
      "True:       [0, 5, 6, 6, 0]\n",
      "---\n",
      "[✓] Sentence 39\n",
      "Tokens:     ['Toledo', '61,514', '0']\n",
      "Predicted:  [5, 0, 0]\n",
      "True:       [5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 40\n",
      "Tokens:     ['Poland', \"'s\", 'ex-communist', 'President', 'Aleksander', 'Kwasniewski', 'is', 'likely', 'to', 'visit', 'Polish-born', 'Pope', 'John', 'Paul', 'in', 'early', '1997', 'despite', 'uneasy', 'relations', 'between', 'the', 'Vatican', 'and', 'Warsaw', ',', 'the', 'foreign', 'minister', 'said', 'on', 'Friday', '.']\n",
      "Predicted:  [5, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 7, 2, 2, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [5, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 41\n",
      "Tokens:     ['5.', 'Florence', 'Masnada', '(', 'France', ')', '82']\n",
      "Predicted:  [0, 1, 0, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 42\n",
      "Tokens:     ['(', '52.91', '/', '53.07', ')']\n",
      "Predicted:  [0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 43\n",
      "Tokens:     ['Napoli', '(', '5', ')', 'v', 'Verona', '(', '17', ')', '1330']\n",
      "Predicted:  [3, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 44\n",
      "Tokens:     ['The', 'Thai', 'Commerce', 'Ministry', 'detailed', 'rice', 'loading', 'at', 'Thai', 'ports', 'as', 'follows', '(', 'in', 'tonnes', ')', ':']\n",
      "Predicted:  [0, 7, 4, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 7, 3, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 45\n",
      "Tokens:     ['The', 'pilot', 'and', 'co-pilot', ',', 'the', 'only', 'two', 'aboard', ',', 'were', 'killed', 'in', 'the', 'crash', 'of', 'the', 'Learjet', '36', ',', 'airport', 'manager', 'David', 'Snow', 'said', 'in', 'a', 'telephone', 'interview', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 46\n",
      "Tokens:     ['He', 'also', 'estimated', 'that', 'only', '25', 'percent', 'of', 'bites', 'were', 'reported', 'because', 'medical', 'attention', 'was', 'not', 'needed', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 47\n",
      "Tokens:     ['Denmark', \"'s\", 'Radiometer', 'H1', 'result', 'seen', 'flat', '.']\n",
      "Predicted:  [5, 0, 7, 8, 0, 0, 0, 0]\n",
      "True:       [5, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 48\n",
      "Tokens:     ['Information', 'technology', 'firm', 'Electronic', 'Data', 'Systems', 'said', 'on', 'Friday', 'it', 'had', 'bagged', 'a', 'contract', 'for', 'the', 'first', 'air', 'traffic', 'control', 'project', 'being', 'funded', 'under', 'the', 'Private', 'Finance', 'Initiative', '.']\n",
      "Predicted:  [0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 8, 8, 0]\n",
      "True:       [0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 49\n",
      "Tokens:     ['B.', 'Lara', 'c', 'Warne', 'b', 'Moody', '5']\n",
      "Predicted:  [1, 2, 0, 1, 0, 0, 0]\n",
      "True:       [1, 2, 0, 1, 0, 1, 0]\n",
      "---\n",
      "[✓] Sentence 50\n",
      "Tokens:     ['MILWAUKEE', 'AT', 'WASHINGTON']\n",
      "Predicted:  [5, 0, 5]\n",
      "True:       [3, 0, 5]\n",
      "---\n",
      "[✓] Sentence 51\n",
      "Tokens:     ['He', 'played', 'an', 'active', 'role', 'at', 'the', 'U.N.', 'social', 'development', 'conference', 'in', 'Copenhagen', 'last', 'year', 'and', 'has', 'co-authored', 'articles', 'with', 'U.N.', 'development', 'programme', 'officer', 'Inge', 'Kaul', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 7, 6, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 2, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 2, 0]\n",
      "---\n",
      "[✓] Sentence 52\n",
      "Tokens:     ['5.', 'Korneilus', 'Hole', '(', 'Norway', ')', '23.92']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 53\n",
      "Tokens:     ['ST', 'LOUIS', '13', '14', '0', '78', '81', '26']\n",
      "Predicted:  [5, 6, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 54\n",
      "Tokens:     ['Premier', 'league']\n",
      "Predicted:  [3, 4]\n",
      "True:       [7, 8]\n",
      "---\n",
      "[✓] Sentence 55\n",
      "Tokens:     ['Extremadura', '15', '1', '3', '11', '8', '30', '6']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 56\n",
      "Tokens:     ['RE', ':', '$', '25,000,000']\n",
      "Predicted:  [0, 0, 7, 0]\n",
      "True:       [0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 57\n",
      "Tokens:     ['Division', 'One']\n",
      "Predicted:  [0, 0]\n",
      "True:       [0, 0]\n",
      "---\n",
      "[✓] Sentence 58\n",
      "Tokens:     ['St', 'Louis', '4', 'COLORADO', '3']\n",
      "Predicted:  [5, 6, 0, 5, 0]\n",
      "True:       [5, 6, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 59\n",
      "Tokens:     ['Hapoel', 'Petah', 'Tikva', '12', '9', '2', '1', '27', '13', '29']\n",
      "Predicted:  [3, 6, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 60\n",
      "Tokens:     ['Marianne', 'Timmer', '(', 'Netherlands', ')', '41.58', ';', '7', '.']\n",
      "Predicted:  [1, 2, 0, 5, 0, 0, 0, 0, 0]\n",
      "True:       [1, 2, 0, 5, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 61\n",
      "Tokens:     ['29.', 'Patrizia', 'Bassis', '(', 'Italy', ')', '1:51.13']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 62\n",
      "Tokens:     ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
      "Predicted:  [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0]\n",
      "True:       [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 63\n",
      "Tokens:     ['9.', 'Martina', 'Ertl', '(', 'Germany', ')', '58']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 64\n",
      "Tokens:     ['Inquiry', 'good', ',', 'demand', 'light', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 65\n",
      "Tokens:     ['SOCCER', '-', 'SPANISH', 'FIRST', 'DIVISION', 'SUMMARY', '.']\n",
      "Predicted:  [0, 3, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 7, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 66\n",
      "Tokens:     ['It', 'was', 'not', 'immediately', 'clear', 'who', 'was', 'behind', 'the', 'blast', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 67\n",
      "Tokens:     ['Woman', 'charged', 'over', 'N.', 'Ireland', 'arms', 'find', '.']\n",
      "Predicted:  [0, 0, 0, 0, 5, 0, 0, 0]\n",
      "True:       [0, 0, 0, 5, 6, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 68\n",
      "Tokens:     ['Bradford', '22', '5', '6', '11', '21', '37', '21']\n",
      "Predicted:  [1, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 69\n",
      "Tokens:     ['It', 'said', 'in', 'a', 'statement', 'that', 'it', 'made', 'profits', 'of', '4.5', 'million', 'kroons', 'in', 'November', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 70\n",
      "Tokens:     ['0-1', '.']\n",
      "Predicted:  [0, 0]\n",
      "True:       [0, 0]\n",
      "---\n",
      "[✓] Sentence 71\n",
      "Tokens:     ['C.', 'Hooper', 'run', 'out', '7']\n",
      "Predicted:  [1, 2, 0, 0, 7]\n",
      "True:       [1, 2, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 72\n",
      "Tokens:     ['Espanyol', '15', '4', '4', '7', '17', '20', '16']\n",
      "Predicted:  [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 73\n",
      "Tokens:     ['He', 'said', 'Bre-X', 'would', 'then', 'formally', 'seek', 'the', 'permission', 'of', 'the', 'Indonesian', 'government', 'to', 'begin', 'construction', 'to', 'develop', 'Busang', \"'s\", 'central', 'region', ',', 'which', 'might', 'take', 'up', 'to', 'two', 'years', '.']\n",
      "Predicted:  [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 74\n",
      "Tokens:     ['Radio', 'Romania', 'news', 'headlines', ':']\n",
      "Predicted:  [0, 5, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 75\n",
      "Tokens:     ['Havel', 'has', 'been', 'recovering', 'from', 'surgery', 'on', 'Monday', 'which', 'removed', 'a', 'small', 'malignant', 'tumour', 'and', 'half', 'of', 'his', 'right', 'lung', '.']\n",
      "Predicted:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 76\n",
      "Tokens:     ['LA', 'CLIPPERS', '7', '11', '.389', '7']\n",
      "Predicted:  [5, 4, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 77\n",
      "Tokens:     ['NAC', 'Breda', '18', '6', '3', '9', '17', '29', '21']\n",
      "Predicted:  [3, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 78\n",
      "Tokens:     ['PORTLAND', '12', '8', '.600', '3']\n",
      "Predicted:  [5, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 79\n",
      "Tokens:     ['An', 'Australian', 'hitman', 'who', 'went', 'to', 'the', 'wrong', 'house', 'and', 'killed', 'the', 'wrong', 'man', 'was', 'sentenced', 'to', '20', 'years', 'jail', 'on', 'Friday', '.']\n",
      "Predicted:  [0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 80\n",
      "Tokens:     ['Dressed', 'Basis', 'Delivered', 'not', 'well', 'tested', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 81\n",
      "Tokens:     ['NY', 'RANGERS', '10', '13', '5', '91', '81', '25']\n",
      "Predicted:  [0, 3, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 82\n",
      "Tokens:     ['Sun', 'Jun', '(', 'China', ')', 'beat', 'Rashid', 'Sidek', '(', 'Malaysia', ')', '15-12', '17-14']\n",
      "Predicted:  [1, 2, 0, 5, 0, 0, 1, 2, 0, 5, 0, 0, 0]\n",
      "True:       [1, 2, 0, 5, 0, 0, 1, 2, 0, 5, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 83\n",
      "Tokens:     ['\"', 'If', 'it', 'was', 'an', 'unsolicited', 'statement', 'and', 'a', 'bolt', 'out', 'of', 'the', 'blue', ',', 'then', 'it', 'obviously', 'means', 'something', ',', '\"', 'said', 'Christopher', 'Granville', ',', 'chief', 'economist', 'at', 'United', 'City', 'Bank', 'in', 'Moscow', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 3, 4, 4, 0, 5, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 3, 4, 4, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 84\n",
      "Tokens:     ['They', 'announced', 'they', 'will', 'start', 'evening', 'sessions', 'next', 'week', '.', '\"']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 85\n",
      "Tokens:     ['AMARILLO', '1996-12-06']\n",
      "Predicted:  [5, 0]\n",
      "True:       [5, 0]\n",
      "---\n",
      "[✓] Sentence 86\n",
      "Tokens:     ['CENTRAL', 'DIVISION']\n",
      "Predicted:  [3, 4]\n",
      "True:       [0, 0]\n",
      "---\n",
      "[✓] Sentence 87\n",
      "Tokens:     ['Some', 'of', 'my', 'brother', 'heads', 'of', 'state', 'asked', 'me', 'if', 'I', 'would', \"n't\", 'nominate', 'Moustapha', 'Niasse', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0]\n",
      "---\n",
      "[✓] Sentence 88\n",
      "Tokens:     ['The', 'protests', 'culminated', 'at', 'dawn', 'on', 'Tuesday', 'with', 'several', 'hundred', 'of', 'the', 'student', 'protesters', 'being', 'detained', 'briefly', 'by', 'police', 'near', 'the', 'central', 'Shwe', 'Dagon', 'pagoda', 'in', 'Rangoon', '.']\n",
      "Predicted:  [0, 0, 0, 5, 6, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 5, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 89\n",
      "Tokens:     ['If', 'he', 'decided', 'it', 'was', 'necessary', 'and', 'safe', 'for', 'the', 'aircrew', ',', 'he', 'would', 'not', 'hesitate', 'to', 'order', 'airdrops', 'of', 'food', 'for', 'the', 'refugees', ',', 'even', 'against', 'the', 'wishes', 'of', 'the', 'government', 'in', 'Kinshasa', 'and', 'the', 'Zairean', 'rebels', 'who', 'control', 'much', 'of', 'eastern', 'Zaire', ',', 'he', 'said', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 8, 0, 5, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 7, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 90\n",
      "Tokens:     ['GLASGOW', '1996-12-07']\n",
      "Predicted:  [5, 0]\n",
      "True:       [5, 0]\n",
      "---\n",
      "[✓] Sentence 91\n",
      "Tokens:     ['SEATTLE', '5', '8', '0', '250', '317']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 92\n",
      "Tokens:     ['CANBERRA', '1996-12-06']\n",
      "Predicted:  [5, 0]\n",
      "True:       [5, 0]\n",
      "---\n",
      "[✓] Sentence 93\n",
      "Tokens:     ['\"', 'This', 'was', 'an', 'act', 'of', 'terrorism', 'and', 'now', 'I', 'fear', 'not', 'only', 'for', 'my', 'own', 'life', ',', 'but', 'also', 'of', 'that', 'of', 'my', 'wife', 'and', 'children', ',', '\"', 'he', 'told', 'TASR', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]\n",
      "---\n",
      "[✓] Sentence 94\n",
      "Tokens:     ['WASHINGTON', '13', '13', '1', '72', '71', '27']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 95\n",
      "Tokens:     ['\"', 'Today', 'we', 'are', 'left', 'with', 'a', 'ruinous', 'wreck', 'beyond', 'salvage', 'and', 'a', 'continuing', 'pall', 'of', 'doubt', 'and', 'suspicion', 'hanging', 'over', 'our', 'diplomatic', 'service', ',', '\"', 'opposition', 'foreign', 'affairs', 'spokesman', 'Laurie', 'Brereton', 'said', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]\n",
      "---\n",
      "[✓] Sentence 96\n",
      "Tokens:     ['AC', 'Milan', '(', '9', ')', 'v', 'Udinese', '(', '11', ')', '1330']\n",
      "Predicted:  [3, 4, 0, 0, 0, 7, 4, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 97\n",
      "Tokens:     ['17.', 'Hilde', 'Gerg', '(', 'Germany', ')', '42']\n",
      "Predicted:  [0, 1, 0, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 98\n",
      "Tokens:     ['RTRS', '-', 'Australian', 'MP', 'John', 'Langmore', 'formally', 'resigns', '.']\n",
      "Predicted:  [3, 0, 7, 0, 1, 2, 0, 0, 0]\n",
      "True:       [3, 0, 7, 0, 1, 2, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 99\n",
      "Tokens:     ['9.', 'Katja', 'Seizinger', '(', 'Germany', ')', '1:18.32']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Initialize client\n",
    "client = Client()\n",
    "\n",
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "\n",
    "    prompt = f\"\"\"You are an expert in Named Entity Recognition (NER). Your task is to assign an entity tag ID to each token in the sentence using the strict schema below.\n",
    "\n",
    "    NER Tag IDs:\n",
    "    - 0 = O → Not an entity  \n",
    "    - 1 = PERSON → Real names, personal titles (e.g., \"Barack\", \"Dr.\", \"Angela\")  \n",
    "    - 3 = ORGANIZATION → Companies, institutions, teams, agencies (e.g., \"Google\", \"United Nations\", \"Lakers\", \"Juventus\")  \n",
    "    - 5 = LOCATION → Cities, countries, natural landmarks, buildings (e.g., \"Paris\", \"Mount Everest\", \"Empire State Building\")  \n",
    "    - 7 = MISCELLANEOUS → Nationalities, languages, events, products, titles of works (e.g., \"Italian\", \"Olympics\", \"iPhone\", \"French\", \"The Matrix\")\n",
    "\n",
    "    ---\n",
    "\n",
    "    Rules:\n",
    "    - Use only contextual evidence to determine entity types.\n",
    "    - If the token does not clearly match a defined type, assign `0 (O)`.\n",
    "    - Please do not assign tags based on assumptions or incomplete context.\n",
    "    - Please be as precise as possible\n",
    "\n",
    "    ---\n",
    "\n",
    "    Now tag the sentence below:\n",
    "    Sentence: {tokens}  \n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "    \n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "\n",
    "    Your answer MUST follow this format:  \n",
    "    ner_tags: 0, 1, 0, 5, 5, 0  \n",
    "    (Must return exactly {len(tokens)} tag IDs in order, no extra text.)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_test_ds/vanilla_test_100_ds_14b_ADVANCEDPOS_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827ee67",
   "metadata": {},
   "source": [
    "### Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03287eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid predictions: 29\n",
      "\n",
      "Precision: 0.37089201877934275\n",
      "Recall: 0.5197368421052632\n",
      "F1 Score: 0.4328767123287671\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.49      0.75      0.59        59\n",
      "        MISC       0.09      0.25      0.13        12\n",
      "         ORG       0.21      0.16      0.18        49\n",
      "         PER       0.46      0.75      0.57        32\n",
      "\n",
      "   micro avg       0.37      0.52      0.43       152\n",
      "   macro avg       0.31      0.48      0.37       152\n",
      "weighted avg       0.36      0.52      0.42       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "label_mapping = {\n",
    "    0: 'O',\n",
    "    1: 'B-PER',\n",
    "    2: 'I-PER',\n",
    "    3: 'B-ORG',\n",
    "    4: 'I-ORG',\n",
    "    5: 'B-LOC',\n",
    "    6: 'I-LOC',\n",
    "    7: 'B-MISC',\n",
    "    8: 'I-MISC'\n",
    "}\n",
    "\n",
    "category_to_index = {\n",
    "    'O': 0,\n",
    "    'B-PER': 1, \n",
    "    'I-PER': 2, \n",
    "    'B-ORG': 3, \n",
    "    'I-ORG': 4, \n",
    "    'B-LOC': 5, \n",
    "    'I-LOC': 6, \n",
    "    'B-MISC': 7, \n",
    "    'I-MISC': 8\n",
    "    }\n",
    "\n",
    "valid_labels = set(label_mapping.values())\n",
    "\n",
    "def evaluate_predictions(filename: str) -> None:\n",
    "    true_seqs = []\n",
    "    pred_seqs = []\n",
    "    current_true = []\n",
    "    current_pred = []\n",
    "    invalid_count = 0\n",
    "\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            true_index = int(row['true'])\n",
    "            pred_index = int(row['pred'])\n",
    "            \n",
    "            true_label = label_mapping.get(true_index, 'O')\n",
    "            pred_label = label_mapping.get(pred_index, 'INVALID')\n",
    "\n",
    "            if pred_label not in valid_labels:\n",
    "                pred_label = 'INVALID'\n",
    "                invalid_count += 1\n",
    "                continue\n",
    "\n",
    "            current_true.append(true_label)\n",
    "            current_pred.append(pred_label)\n",
    "\n",
    "        true_seqs.append(current_true)\n",
    "        pred_seqs.append(current_pred)\n",
    "\n",
    "    print(f\"Invalid predictions: {invalid_count}\\n\")\n",
    "\n",
    "    print(\"Precision:\", precision_score(true_seqs, pred_seqs))\n",
    "    print(\"Recall:\", recall_score(true_seqs, pred_seqs))\n",
    "    print(\"F1 Score:\", f1_score(true_seqs, pred_seqs))\n",
    "\n",
    "    print(\"\\nDetailed classification report:\\n\")\n",
    "    print(classification_report(true_seqs, pred_seqs))\n",
    "\n",
    "\n",
    "evaluate_predictions('data100_test_ds/vanilla_test_100_ds_14b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab78c86",
   "metadata": {},
   "source": [
    "### Using the test set on the vanilla prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e513dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Sentence 0\n",
      "Tokens:     ['\"', 'The', 'recent', 'level', 'of', 'the', 'yen', 'exchange', 'rate', 'has', 'been', 'stable', ',', 'and', 'it', 'does', 'not', 'appear', 'to', 'be', 'moving', 'towards', 'a', 'further', 'depreciation', 'of', 'the', 'yen', 'immediately', ',', 'so', 'import', 'prices', 'are', 'likely', 'to', 'stabilise', 'at', 'current', 'levels', ',', '\"', 'Matsushita', 'said', 'in', 'an', 'interview', 'with', 'the', 'Nihon', 'Keizai', 'Shimbun', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0]\n",
      "---\n",
      "[✓] Sentence 1\n",
      "Tokens:     ['Blackpool', '0', 'Hednesford', '1']\n",
      "Predicted:  [5, 0, 5, 0]\n",
      "True:       [3, 0, 3, 0]\n",
      "---\n",
      "[✓] Sentence 2\n",
      "Tokens:     ['Wheat', '387.4', '4677.8', '4553.6', '55.2', '1039.7', '846.1']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 3\n",
      "Tokens:     ['Ulker', 'Spor', '(', 'Turkey', ')', '9', '4', '5', '13']\n",
      "Predicted:  [3, 4, 0, 5, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 5, 0, 0, 0, 0, 0]\n",
      "---\n",
      "Token: conference, Predicted Label: 9, True Label: 0\n",
      "Token: :, Predicted Label: 10, True Label: 0\n",
      "Token: \", Predicted Label: 11, True Label: 0\n",
      "Token: I, Predicted Label: 12, True Label: 0\n",
      "Token: have, Predicted Label: 13, True Label: 0\n",
      "Token: seen, Predicted Label: 14, True Label: 0\n",
      "Token: my, Predicted Label: 15, True Label: 0\n",
      "Token: whip, Predicted Label: 16, True Label: 0\n",
      "Token: (, Predicted Label: 17, True Label: 0\n",
      "Token: party, Predicted Label: 18, True Label: 0\n",
      "Token: manager, Predicted Label: 19, True Label: 0\n",
      "Token: ), Predicted Label: 20, True Label: 0\n",
      "Token: for, Predicted Label: 21, True Label: 0\n",
      "Token: next, Predicted Label: 22, True Label: 0\n",
      "Token: week, Predicted Label: 23, True Label: 0\n",
      "Token: which, Predicted Label: 24, True Label: 0\n",
      "Token: ,, Predicted Label: 25, True Label: 0\n",
      "Token: of, Predicted Label: 26, True Label: 0\n",
      "Token: course, Predicted Label: 27, True Label: 0\n",
      "Token: ,, Predicted Label: 28, True Label: 0\n",
      "Token: does, Predicted Label: 29, True Label: 0\n",
      "Token: n't, Predicted Label: 30, True Label: 0\n",
      "Token: mean, Predicted Label: 31, True Label: 0\n",
      "Token: very, Predicted Label: 32, True Label: 0\n",
      "Token: much, Predicted Label: 33, True Label: 0\n",
      "Token: to, Predicted Label: 34, True Label: 0\n",
      "Token: me, Predicted Label: 35, True Label: 0\n",
      "Token: now, Predicted Label: 36, True Label: 0\n",
      "Token: ., Predicted Label: 37, True Label: 0\n",
      "[✓] Sentence 4\n",
      "Tokens:     ['He', 'said', 'at', 'one', 'point', 'during', 'a', 'press', 'conference', ':', '\"', 'I', 'have', 'seen', 'my', 'whip', '(', 'party', 'manager', ')', 'for', 'next', 'week', 'which', ',', 'of', 'course', ',', 'does', \"n't\", 'mean', 'very', 'much', 'to', 'me', 'now', '.', '\"']\n",
      "Predicted:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 1]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 5\n",
      "Tokens:     ['Alexander', 'Bavykin', ',', 'deputy', 'legal', 'chief', 'at', 'Russia', \"'s\", 'foreign', 'ministry', ',', 'said', 'Moscow', 'had', 'yet', 'to', 'formulate', 'a', 'policy', 'on', 'copyright', 'in', 'cybersppace', '.']\n",
      "Predicted:  [1, 2, 0, 0, 0, 0, 0, 5, 0, 3, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [1, 2, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 6\n",
      "Tokens:     ['Turkey', 'says', 'Syria', 'sponsors', 'the', 'PKK', ',', 'fighting', 'for', 'Kurdish', 'self-rule', 'in', 'southeast', 'Turkey', '.']\n",
      "Predicted:  [5, 0, 5, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 5, 0]\n",
      "True:       [5, 0, 5, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 7\n",
      "Tokens:     ['--', 'U.S.', 'Municipal', 'Desk', ',', '212-859-1650']\n",
      "Predicted:  [0, 5, 0, 0, 0, 7]\n",
      "True:       [0, 3, 4, 4, 0, 0]\n",
      "---\n",
      "[✓] Sentence 8\n",
      "Tokens:     ['Hapoel', 'Beit', \"She'an\", '2', 'Hapoel', 'Beersheba', '1']\n",
      "Predicted:  [3, 0, 5, 0, 3, 5, 0]\n",
      "True:       [3, 4, 4, 0, 3, 4, 0]\n",
      "---\n",
      "[✓] Sentence 9\n",
      "Tokens:     ['Real', 'Madrid', \"'s\", 'Balkan', 'strike', 'force', 'of', 'Davor', 'Suker', 'and', 'Predrag', 'Mijatovic', 'shot', 'their', 'side', 'to', 'a', '2-0', 'win', 'over', 'Barcelona', 'in', 'Spain', \"'s\", 'old', 'firm', 'game', 'on', 'Saturday', '.']\n",
      "Predicted:  [3, 4, 4, 5, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 5, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 10\n",
      "Tokens:     ['\"', 'French', 'troops', 'may', 'only', 'take', 'part', 'in', 'maintaining', 'order', 'to', 'avoid', 'major', 'abuses', 'and', 'protect', 'foreign', 'communities', ',', '\"', 'he', 'said', '.']\n",
      "Predicted:  [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 11\n",
      "Tokens:     ['Two', 'people', 'were', 'killed', 'when', 'an', 'executive', 'jet', 'en', 'route', 'to', 'Ireland', 'from', 'Michigan', 'crashed', 'on', 'approach', 'to', 'an', 'airport', 'in', 'Stephenville', ',', 'Newfoundland', ',', 'on', 'Friday', ',', 'authorities', 'said', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 0, 0, 0, 0, 6, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 12\n",
      "Tokens:     [\"'\", \"'\", 'In', 'January', 'or', 'February', ',', 'we', \"'ll\", 'have', 'some', 'very', 'close', 'contacts', 'with', 'Mexico', 'to', 'add', 'the', 'issue', 'of', 'services', 'and', 'advance', 'on', 'the', 'issue', 'of', 'investments', ',', \"'\", \"'\", 'Aninat', 'told', 'reporters', 'after', 'signing', 'a', 'free', 'trade', 'deal', 'with', 'Canada', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 13\n",
      "Tokens:     ['Name', ':', 'Svetlana', 'Gladishiva']\n",
      "Predicted:  [0, 0, 1, 2]\n",
      "True:       [0, 0, 1, 2]\n",
      "---\n",
      "[✓] Sentence 14\n",
      "Tokens:     ['\"', 'I', 'look', 'forward', 'to', 'continuing', 'our', 'good', 'relations', '...']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 7, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 15\n",
      "Tokens:     ['A', 'New', 'Mexico', 'high', 'school', 'football', 'player', 'who', 'used', 'razor-sharp', 'helmet', 'buckles', 'to', 'slash', 'opponents', 'and', 'a', 'referee', 'was', 'expelled', 'from', 'high', 'school', 'banned', 'Thursday', 'from', 'competition', 'for', 'one', 'year', '.']\n",
      "Predicted:  [0, 5, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 16\n",
      "Tokens:     ['Standings', '(', 'tabulate', 'under', 'played', ',', 'won', ',', 'drawn', ',', 'lost', ',', 'goals']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 17\n",
      "Tokens:     ['Santa', 'Fe', 'is', 'so', 'far', 'mum', 'on', 'the', 'more', 'than', '$', '2', 'billion', 'stock', 'swap', 'takeover', 'proposal', 'from', 'Newmont', ',', 'announced', 'Thursday', '.']\n",
      "Predicted:  [5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 8, 8, 8, 8, 8, 0, 3, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 18\n",
      "Tokens:     ['PSV', 'Eindhoven', '18', '13', '3', '2', '52', '14', '42']\n",
      "Predicted:  [0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 19\n",
      "Tokens:     ['Ipswich', '0', 'Wolverhampton', '0']\n",
      "Predicted:  [5, 0, 5, 0]\n",
      "True:       [3, 0, 3, 0]\n",
      "---\n",
      "[✓] Sentence 20\n",
      "Tokens:     ['VANCOUVER', '14', '11', '1', '84', '83', '29']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 21\n",
      "Tokens:     ['Saturday', \"'s\", 'women', \"'s\", 'World', 'Cup', 'downhill', 'race', ':']\n",
      "Predicted:  [0, 0, 7, 0, 8, 8, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 7, 8, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 22\n",
      "Tokens:     ['TORONTO', '6', '11', '.353', '10', '1/2']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 23\n",
      "Tokens:     ['LONDON', '1996-12-06']\n",
      "Predicted:  [5, 0]\n",
      "True:       [5, 0]\n",
      "---\n",
      "[✓] Sentence 24\n",
      "Tokens:     ['There', 'was', 'no', 'Bundesbank', 'intervention', '.']\n",
      "Predicted:  [0, 0, 0, 3, 4, 0]\n",
      "True:       [0, 0, 0, 3, 0, 0]\n",
      "---\n",
      "[✓] Sentence 25\n",
      "Tokens:     ['15,232']\n",
      "Predicted:  [0]\n",
      "True:       [0]\n",
      "---\n",
      "[✓] Sentence 26\n",
      "Tokens:     ['NEW', 'YORK', '1996-12-07']\n",
      "Predicted:  [5, 6, 8]\n",
      "True:       [5, 6, 0]\n",
      "---\n",
      "[✓] Sentence 27\n",
      "Tokens:     ['10=', 'Florence', 'Masnada', '(', 'France', ')', '51']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 5, 1, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 28\n",
      "Tokens:     ['Bayern', 'Munich', '16', '9', '6', '1', '26', '14', '33']\n",
      "Predicted:  [3, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 29\n",
      "Tokens:     ['The', 'freak', 'accident', 'occurred', 'in', 'Mafikeng', 'on', 'Thursday', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 5, 0, 7, 0]\n",
      "True:       [0, 0, 0, 0, 0, 5, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 30\n",
      "Tokens:     ['NEW', 'YORK', '1996-12-06']\n",
      "Predicted:  [5, 6, 0]\n",
      "True:       [5, 6, 0]\n",
      "---\n",
      "[✓] Sentence 31\n",
      "Tokens:     ['Southend', '22', '5', '9', '8', '23', '36', '24']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 32\n",
      "Tokens:     ['The', 'West', 'Indies', 'vice-captain', 'struggled', 'for', 'timing', 'during', 'his', '36-minute', 'stay', 'at', 'the', 'crease', 'before', 'chipping', 'a', 'ball', 'from', 'medium', 'pacer', 'Tom', 'Moody', 'straight', 'to', 'Shane', 'Warne', 'at', 'mid-wicket', '.']\n",
      "Predicted:  [0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0]\n",
      "True:       [0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 33\n",
      "Tokens:     ['Results', 'of', 'Northern', 'Ireland', 'premier']\n",
      "Predicted:  [0, 0, 5, 6, 0]\n",
      "True:       [0, 0, 5, 6, 0]\n",
      "---\n",
      "[✓] Sentence 34\n",
      "Tokens:     ['December', '25', ',', 'a', 'normal', 'working', 'day', 'in', 'Russia', ',', 'is', 'the', 'fifth', 'anniversary', 'of', 'Yeltsin', \"'s\", 'arrival', 'in', 'the', 'Kremlin', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 35\n",
      "Tokens:     ['Salomon', \"'s\", 'bond', 'index', 'is', 'calculated', 'using', 'all', 'government', 'bonds', 'with', 'over', 'one', 'year', 'to', 'maturity', ',', 'weighted', 'for', 'market', 'capitalisation', '.']\n",
      "Predicted:  [1, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 36\n",
      "Tokens:     ['China', \"'s\", 'tourist', 'spot', 'of', 'Guilin', 'in', 'the', 'southern', 'region', 'of', 'Guangxi', 'will', 'open', 'its', 'airport', 'to', 'foreign', 'aircraft', ',', 'the', 'Xinhua', 'news', 'agency', 'said', 'on', 'Friday', '.']\n",
      "Predicted:  [5, 6, 0, 0, 0, 5, 0, 0, 0, 0, 6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 7, 0]\n",
      "True:       [5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 37\n",
      "Tokens:     ['Phoenix', '3', 'ST', 'LOUIS', '0']\n",
      "Predicted:  [5, 0, 0, 1, 0]\n",
      "True:       [3, 0, 3, 4, 0]\n",
      "---\n",
      "[✓] Sentence 38\n",
      "Tokens:     ['-', 'Gulf', 'of', 'Mexico', ':']\n",
      "Predicted:  [0, 1, 0, 6, 0]\n",
      "True:       [0, 5, 6, 6, 0]\n",
      "---\n",
      "[✓] Sentence 39\n",
      "Tokens:     ['Toledo', '61,514', '0']\n",
      "Predicted:  [5, 0, 0]\n",
      "True:       [5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 40\n",
      "Tokens:     ['Poland', \"'s\", 'ex-communist', 'President', 'Aleksander', 'Kwasniewski', 'is', 'likely', 'to', 'visit', 'Polish-born', 'Pope', 'John', 'Paul', 'in', 'early', '1997', 'despite', 'uneasy', 'relations', 'between', 'the', 'Vatican', 'and', 'Warsaw', ',', 'the', 'foreign', 'minister', 'said', 'on', 'Friday', '.']\n",
      "Predicted:  [5, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [5, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 41\n",
      "Tokens:     ['5.', 'Florence', 'Masnada', '(', 'France', ')', '82']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 42\n",
      "Tokens:     ['(', '52.91', '/', '53.07', ')']\n",
      "Predicted:  [0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 43\n",
      "Tokens:     ['Napoli', '(', '5', ')', 'v', 'Verona', '(', '17', ')', '1330']\n",
      "Predicted:  [5, 0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 44\n",
      "Tokens:     ['The', 'Thai', 'Commerce', 'Ministry', 'detailed', 'rice', 'loading', 'at', 'Thai', 'ports', 'as', 'follows', '(', 'in', 'tonnes', ')', ':']\n",
      "Predicted:  [0, 5, 3, 4, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 7, 3, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 45\n",
      "Tokens:     ['The', 'pilot', 'and', 'co-pilot', ',', 'the', 'only', 'two', 'aboard', ',', 'were', 'killed', 'in', 'the', 'crash', 'of', 'the', 'Learjet', '36', ',', 'airport', 'manager', 'David', 'Snow', 'said', 'in', 'a', 'telephone', 'interview', '.']\n",
      "Predicted:  [0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 46\n",
      "Tokens:     ['He', 'also', 'estimated', 'that', 'only', '25', 'percent', 'of', 'bites', 'were', 'reported', 'because', 'medical', 'attention', 'was', 'not', 'needed', '.']\n",
      "Predicted:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 47\n",
      "Tokens:     ['Denmark', \"'s\", 'Radiometer', 'H1', 'result', 'seen', 'flat', '.']\n",
      "Predicted:  [5, 0, 3, 4, 0, 0, 0, 0]\n",
      "True:       [5, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 48\n",
      "Tokens:     ['Information', 'technology', 'firm', 'Electronic', 'Data', 'Systems', 'said', 'on', 'Friday', 'it', 'had', 'bagged', 'a', 'contract', 'for', 'the', 'first', 'air', 'traffic', 'control', 'project', 'being', 'funded', 'under', 'the', 'Private', 'Finance', 'Initiative', '.']\n",
      "Predicted:  [0, 0, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 8, 0, 0, 0, 0, 0, 7, 8, 8]\n",
      "True:       [0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 49\n",
      "Tokens:     ['B.', 'Lara', 'c', 'Warne', 'b', 'Moody', '5']\n",
      "Predicted:  [0, 1, 0, 1, 0, 1, 0]\n",
      "True:       [1, 2, 0, 1, 0, 1, 0]\n",
      "---\n",
      "[✓] Sentence 50\n",
      "Tokens:     ['MILWAUKEE', 'AT', 'WASHINGTON']\n",
      "Predicted:  [5, 0, 5]\n",
      "True:       [3, 0, 5]\n",
      "---\n",
      "[✓] Sentence 51\n",
      "Tokens:     ['He', 'played', 'an', 'active', 'role', 'at', 'the', 'U.N.', 'social', 'development', 'conference', 'in', 'Copenhagen', 'last', 'year', 'and', 'has', 'co-authored', 'articles', 'with', 'U.N.', 'development', 'programme', 'officer', 'Inge', 'Kaul', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 1, 2, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 2, 0]\n",
      "---\n",
      "[✓] Sentence 52\n",
      "Tokens:     ['5.', 'Korneilus', 'Hole', '(', 'Norway', ')', '23.92']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 53\n",
      "Tokens:     ['ST', 'LOUIS', '13', '14', '0', '78', '81', '26']\n",
      "Predicted:  [0, 1, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 54\n",
      "Tokens:     ['Premier', 'league']\n",
      "Predicted:  [3, 4]\n",
      "True:       [7, 8]\n",
      "---\n",
      "[✓] Sentence 55\n",
      "Tokens:     ['Extremadura', '15', '1', '3', '11', '8', '30', '6']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 56\n",
      "Tokens:     ['RE', ':', '$', '25,000,000']\n",
      "Predicted:  [0, 0, 7, 8]\n",
      "True:       [0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 57\n",
      "Tokens:     ['Division', 'One']\n",
      "Predicted:  [3, 4]\n",
      "True:       [0, 0]\n",
      "---\n",
      "[✓] Sentence 58\n",
      "Tokens:     ['St', 'Louis', '4', 'COLORADO', '3']\n",
      "Predicted:  [5, 6, 0, 5, 0]\n",
      "True:       [5, 6, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 59\n",
      "Tokens:     ['Hapoel', 'Petah', 'Tikva', '12', '9', '2', '1', '27', '13', '29']\n",
      "Predicted:  [3, 5, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 60\n",
      "Tokens:     ['Marianne', 'Timmer', '(', 'Netherlands', ')', '41.58', ';', '7', '.']\n",
      "Predicted:  [1, 2, 0, 5, 0, 0, 0, 0, 0]\n",
      "True:       [1, 2, 0, 5, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 61\n",
      "Tokens:     ['29.', 'Patrizia', 'Bassis', '(', 'Italy', ')', '1:51.13']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 62\n",
      "Tokens:     ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
      "Predicted:  [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 3, 5, 0]\n",
      "True:       [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 63\n",
      "Tokens:     ['9.', 'Martina', 'Ertl', '(', 'Germany', ')', '58']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 64\n",
      "Tokens:     ['Inquiry', 'good', ',', 'demand', 'light', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 65\n",
      "Tokens:     ['SOCCER', '-', 'SPANISH', 'FIRST', 'DIVISION', 'SUMMARY', '.']\n",
      "Predicted:  [0, 0, 7, 0, 0, 0, 0]\n",
      "True:       [0, 0, 7, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 66\n",
      "Tokens:     ['It', 'was', 'not', 'immediately', 'clear', 'who', 'was', 'behind', 'the', 'blast', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 7, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 67\n",
      "Tokens:     ['Woman', 'charged', 'over', 'N.', 'Ireland', 'arms', 'find', '.']\n",
      "Predicted:  [0, 0, 0, 5, 6, 0, 0, 0]\n",
      "True:       [0, 0, 0, 5, 6, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 68\n",
      "Tokens:     ['Bradford', '22', '5', '6', '11', '21', '37', '21']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 69\n",
      "Tokens:     ['It', 'said', 'in', 'a', 'statement', 'that', 'it', 'made', 'profits', 'of', '4.5', 'million', 'kroons', 'in', 'November', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 70\n",
      "Tokens:     ['0-1', '.']\n",
      "Predicted:  [0, 0]\n",
      "True:       [0, 0]\n",
      "---\n",
      "[✓] Sentence 71\n",
      "Tokens:     ['C.', 'Hooper', 'run', 'out', '7']\n",
      "Predicted:  [0, 1, 0, 0, 0]\n",
      "True:       [1, 2, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 72\n",
      "Tokens:     ['Espanyol', '15', '4', '4', '7', '17', '20', '16']\n",
      "Predicted:  [7, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 73\n",
      "Tokens:     ['He', 'said', 'Bre-X', 'would', 'then', 'formally', 'seek', 'the', 'permission', 'of', 'the', 'Indonesian', 'government', 'to', 'begin', 'construction', 'to', 'develop', 'Busang', \"'s\", 'central', 'region', ',', 'which', 'might', 'take', 'up', 'to', 'two', 'years', '.']\n",
      "Predicted:  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 74\n",
      "Tokens:     ['Radio', 'Romania', 'news', 'headlines', ':']\n",
      "Predicted:  [3, 4, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 75\n",
      "Tokens:     ['Havel', 'has', 'been', 'recovering', 'from', 'surgery', 'on', 'Monday', 'which', 'removed', 'a', 'small', 'malignant', 'tumour', 'and', 'half', 'of', 'his', 'right', 'lung', '.']\n",
      "Predicted:  [1, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 76\n",
      "Tokens:     ['LA', 'CLIPPERS', '7', '11', '.389', '7']\n",
      "Predicted:  [5, 3, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 77\n",
      "Tokens:     ['NAC', 'Breda', '18', '6', '3', '9', '17', '29', '21']\n",
      "Predicted:  [0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 78\n",
      "Tokens:     ['PORTLAND', '12', '8', '.600', '3']\n",
      "Predicted:  [5, 7, 7, 7, 7]\n",
      "True:       [3, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 79\n",
      "Tokens:     ['An', 'Australian', 'hitman', 'who', 'went', 'to', 'the', 'wrong', 'house', 'and', 'killed', 'the', 'wrong', 'man', 'was', 'sentenced', 'to', '20', 'years', 'jail', 'on', 'Friday', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 7, 0]\n",
      "True:       [0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 80\n",
      "Tokens:     ['Dressed', 'Basis', 'Delivered', 'not', 'well', 'tested', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 81\n",
      "Tokens:     ['NY', 'RANGERS', '10', '13', '5', '91', '81', '25']\n",
      "Predicted:  [5, 3, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 4, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 82\n",
      "Tokens:     ['Sun', 'Jun', '(', 'China', ')', 'beat', 'Rashid', 'Sidek', '(', 'Malaysia', ')', '15-12', '17-14']\n",
      "Predicted:  [1, 2, 0, 5, 0, 0, 1, 2, 0, 5, 0, 0, 0]\n",
      "True:       [1, 2, 0, 5, 0, 0, 1, 2, 0, 5, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 83\n",
      "Tokens:     ['\"', 'If', 'it', 'was', 'an', 'unsolicited', 'statement', 'and', 'a', 'bolt', 'out', 'of', 'the', 'blue', ',', 'then', 'it', 'obviously', 'means', 'something', ',', '\"', 'said', 'Christopher', 'Granville', ',', 'chief', 'economist', 'at', 'United', 'City', 'Bank', 'in', 'Moscow', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 3, 4, 4, 0, 5, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 3, 4, 4, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 84\n",
      "Tokens:     ['They', 'announced', 'they', 'will', 'start', 'evening', 'sessions', 'next', 'week', '.', '\"']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 85\n",
      "Tokens:     ['AMARILLO', '1996-12-06']\n",
      "Predicted:  [5, 7]\n",
      "True:       [5, 0]\n",
      "---\n",
      "[✓] Sentence 86\n",
      "Tokens:     ['CENTRAL', 'DIVISION']\n",
      "Predicted:  [0, 0]\n",
      "True:       [0, 0]\n",
      "---\n",
      "[✓] Sentence 87\n",
      "Tokens:     ['Some', 'of', 'my', 'brother', 'heads', 'of', 'state', 'asked', 'me', 'if', 'I', 'would', \"n't\", 'nominate', 'Moustapha', 'Niasse', '.']\n",
      "Predicted:  [1, 2, 1, 1, 2, 3, 0, 0, 1, 0, 2, 0, 3, 1, 4, 0, 5]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0]\n",
      "---\n",
      "[✓] Sentence 88\n",
      "Tokens:     ['The', 'protests', 'culminated', 'at', 'dawn', 'on', 'Tuesday', 'with', 'several', 'hundred', 'of', 'the', 'student', 'protesters', 'being', 'detained', 'briefly', 'by', 'police', 'near', 'the', 'central', 'Shwe', 'Dagon', 'pagoda', 'in', 'Rangoon', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 7, 0, 0, 3, 4, 5, 6, 0, 8, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 5, 0]\n",
      "---\n",
      "[✓] Sentence 89\n",
      "Tokens:     ['If', 'he', 'decided', 'it', 'was', 'necessary', 'and', 'safe', 'for', 'the', 'aircrew', ',', 'he', 'would', 'not', 'hesitate', 'to', 'order', 'airdrops', 'of', 'food', 'for', 'the', 'refugees', ',', 'even', 'against', 'the', 'wishes', 'of', 'the', 'government', 'in', 'Kinshasa', 'and', 'the', 'Zairean', 'rebels', 'who', 'control', 'much', 'of', 'eastern', 'Zaire', ',', 'he', 'said', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 7, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 90\n",
      "Tokens:     ['GLASGOW', '1996-12-07']\n",
      "Predicted:  [5, 0]\n",
      "True:       [5, 0]\n",
      "---\n",
      "[✓] Sentence 91\n",
      "Tokens:     ['SEATTLE', '5', '8', '0', '250', '317']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 92\n",
      "Tokens:     ['CANBERRA', '1996-12-06']\n",
      "Predicted:  [5, 7]\n",
      "True:       [5, 0]\n",
      "---\n",
      "[✓] Sentence 93\n",
      "Tokens:     ['\"', 'This', 'was', 'an', 'act', 'of', 'terrorism', 'and', 'now', 'I', 'fear', 'not', 'only', 'for', 'my', 'own', 'life', ',', 'but', 'also', 'of', 'that', 'of', 'my', 'wife', 'and', 'children', ',', '\"', 'he', 'told', 'TASR', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]\n",
      "---\n",
      "[✓] Sentence 94\n",
      "Tokens:     ['WASHINGTON', '13', '13', '1', '72', '71', '27']\n",
      "Predicted:  [5, 0, 0, 0, 0, 0, 0]\n",
      "True:       [3, 0, 0, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 95\n",
      "Tokens:     ['\"', 'Today', 'we', 'are', 'left', 'with', 'a', 'ruinous', 'wreck', 'beyond', 'salvage', 'and', 'a', 'continuing', 'pall', 'of', 'doubt', 'and', 'suspicion', 'hanging', 'over', 'our', 'diplomatic', 'service', ',', '\"', 'opposition', 'foreign', 'affairs', 'spokesman', 'Laurie', 'Brereton', 'said', '.']\n",
      "Predicted:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0]\n",
      "True:       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]\n",
      "---\n",
      "[✓] Sentence 96\n",
      "Tokens:     ['AC', 'Milan', '(', '9', ')', 'v', 'Udinese', '(', '11', ')', '1330']\n",
      "Predicted:  [3, 4, 0, 7, 0, 0, 3, 0, 7, 0, 7]\n",
      "True:       [3, 4, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 97\n",
      "Tokens:     ['17.', 'Hilde', 'Gerg', '(', 'Germany', ')', '42']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n",
      "[✓] Sentence 98\n",
      "Tokens:     ['RTRS', '-', 'Australian', 'MP', 'John', 'Langmore', 'formally', 'resigns', '.']\n",
      "Predicted:  [0, 0, 5, 0, 1, 2, 0, 0, 0]\n",
      "True:       [3, 0, 7, 0, 1, 2, 0, 0, 0]\n",
      "---\n",
      "[✓] Sentence 99\n",
      "Tokens:     ['9.', 'Katja', 'Seizinger', '(', 'Germany', ')', '1:18.32']\n",
      "Predicted:  [0, 1, 2, 0, 5, 0, 0]\n",
      "True:       [0, 1, 2, 0, 5, 0, 0]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Initialize client\n",
    "client = Client()\n",
    "\n",
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_test_ds/vanilla_test_100_ds_14b.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insetti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
