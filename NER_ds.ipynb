{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea07dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-genai\n",
    "!pip install pydantic\n",
    "!pip install seqeval\n",
    "!pip install google-generativeai\n",
    "!pip install datasets[all]\n",
    "!pip install pandas\n",
    "!pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f932fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(0)\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"eriktks/conll2003\")\n",
    "\n",
    "# Access the train, validation, and test splits\n",
    "train_data = dataset[\"train\"]\n",
    "validation_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# Print a sample\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48761050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def parse_response(tokens : list, response_labels : list, true_labels : list) -> list: \n",
    "    '''\n",
    "    Store the response in a list of lists where the first element is the token, the second element \n",
    "    is the predicted label and the third is the true label\n",
    "    '''\n",
    "    response_labels = response_labels.split(\":\")\n",
    "    response_labels = response_labels[1].strip('\\n').split(',')\n",
    "    if (len(response_labels) != len(tokens)):\n",
    "        if (len(response_labels) > len(tokens)):\n",
    "            response_labels = response_labels[:len(tokens)]\n",
    "        if (len(response_labels) < len(tokens)):\n",
    "            response_labels = response_labels + ['0'] * (len(tokens) - len(response_labels))\n",
    "\n",
    "    temp = []\n",
    "    for i in range(len(tokens)):\n",
    "        pred_label = int(response_labels[i].strip())\n",
    "        if(pred_label < 0 or pred_label > 8):\n",
    "            print(f\"Token: {tokens[i]}, Predicted Label: {pred_label}, True Label: {true_labels[i]}\")\n",
    "        #assert (pred_label >= 0 and pred_label <= 8), \"Predicted label is out of range\"\n",
    "        temp.append([tokens[i], pred_label, true_labels[i]])\n",
    "\n",
    "    return temp\n",
    "\n",
    "def save_to_csv_vanilla(tokens : list, pred_labels : list, true_labels : list, filename : str) -> None:\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    # Write header only if the file didn't exist before\n",
    "    if not file_exists:\n",
    "        with open(filename, 'a', newline='') as csvfile:\n",
    "            header = ['token', 'pred', 'true']\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(header)\n",
    "    if (len(pred_labels) == 0 and len(true_labels) == 0):\n",
    "        return\n",
    "    data = [[tokens[i], pred_labels[i], true_labels[i]] for i in range(len(tokens)) if pred_labels[i] != 0 or true_labels[i] != 0]\n",
    "    # Remove duplicates\n",
    "    # Open the file in append mode and write data to analysis purpose\n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85554d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "begin_tags = {1,3,5,7}\n",
    "\n",
    "def parse_response_no_bio(tokens : list, response_labels : list, true_labels : list) -> list: \n",
    "    '''\n",
    "    Store the response in a list of lists where the first element is the token, the second element \n",
    "    is the predicted label and the third is the true label\n",
    "    '''\n",
    "    response_labels = response_labels.split(\":\")\n",
    "    response_labels = response_labels[1].strip('\\n').split(',')\n",
    "    if (len(response_labels) != len(tokens)):\n",
    "        if (len(response_labels) > len(tokens)):\n",
    "            response_labels = response_labels[:len(tokens)]\n",
    "        if (len(response_labels) < len(tokens)):\n",
    "            response_labels = response_labels + ['0'] * (len(tokens) - len(response_labels))\n",
    "\n",
    "    temp = []\n",
    "    for i in range(len(tokens)):\n",
    "        if i > 0 and temp[i-1][1] in begin_tags and int(response_labels[i].strip()) in begin_tags:\n",
    "            # If the previous token is a begin tag and this is not '0', we assume it's a continuation\n",
    "            pred_label = int(response_labels[i].strip()) + 1\n",
    "        elif i > 0 and int(response_labels[i].strip()) in begin_tags and (temp[i-1][1] - 1) == int(response_labels[i].strip()):\n",
    "            # if previous token is an inside token and the current is in the same category, we assume it's a continuation\n",
    "            pred_label = int(response_labels[i].strip()) + 1\n",
    "        else:\n",
    "            # Otherwise, we take the label as is\n",
    "            pred_label = int(response_labels[i].strip())\n",
    "        if(pred_label < 0 or pred_label > 8):\n",
    "            print(f\"Token: {tokens[i]}, Predicted Label: {pred_label}, True Label: {true_labels[i]}\")\n",
    "        #assert (pred_label >= 0 and pred_label <= 8), \"Predicted label is out of range\"\n",
    "        temp.append([tokens[i], pred_label, true_labels[i]])\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take predicted labels and for each token save the label in a list to be used for voting\n",
    "def store_predicted_labels(pred_labels : list, votes : list) -> None:\n",
    "    for i in range(len(pred_labels)):\n",
    "        votes[i].append(pred_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# Sample 100 random elements from the test set\n",
    "sampled_test_data = random.sample(list(test_data), 100)\n",
    "\n",
    "# Print the first few samples to verify\n",
    "for i, sample in enumerate(sampled_test_data[:5]):  # Display the first 5 samples\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(sample)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cbb461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "dependency_trees = []\n",
    "\n",
    "for sample in sampled_test_data:\n",
    "    tokens = sample[\"tokens\"]\n",
    "    sentence = \" \".join(tokens)\n",
    "    doc = nlp(sentence)\n",
    "    tree = [\n",
    "        {\n",
    "            \"text\": token.text,\n",
    "            \"dep\": token.dep_,\n",
    "            \"head\": token.head.text,\n",
    "            \"pos\": token.pos_,\n",
    "            \"index\": token.i,\n",
    "            \"head_index\": token.head.i\n",
    "        }\n",
    "        for token in doc\n",
    "    ]\n",
    "    dependency_trees.append(tree)\n",
    "\n",
    "# Link the two lists\n",
    "for i, sample in enumerate(sampled_test_data):\n",
    "    sample['dependency_tree'] = dependency_trees[i]\n",
    "\n",
    "# Now each sample has the tree inside\n",
    "print(sampled_test_data[0]['dependency_tree'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from ollama import Client\n",
    "\n",
    "# Initialize client\n",
    "client = Client()\n",
    "\n",
    "def clean_response(text):\n",
    "    \"\"\"Cleans the model's output to extract only the numbers.\"\"\"\n",
    "    # Remove <think>...</think> blocks\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Look for the pattern 'ner_tags: 0, 1, 2, ...'\n",
    "    match = re.search(r'ner_tags\\s*:\\s*([0-9,\\s]+)', cleaned)\n",
    "    if match:\n",
    "        number_str = match.group(1)\n",
    "    else:\n",
    "        # If 'ner_tags:' is not found, but there are still numbers, extract them all\n",
    "        number_str = cleaned\n",
    "\n",
    "    # Extract all integers as strings\n",
    "    number_list = re.findall(r'\\d+', number_str)\n",
    "    return number_list\n",
    "\n",
    "\n",
    "def format_example(ex):\n",
    "    return f\"\"\"Tokens: {ex['tokens']}\n",
    "POS tags: {ex['pos_tags']}\n",
    "NER tags: {ex['ner_tags']}\"\"\"\n",
    "\n",
    "# Using 3 random examples in the prompt\n",
    "example1 = train_data[11000]\n",
    "example2 = train_data[12000]\n",
    "example3 = train_data[13000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example_NOBIO(ex):\n",
    "    # Mappa BIO in NOBIO per gli esempi\n",
    "    bio_to_nobio = {0: 0, 1: 1, 2: 1, 3: 3, 4: 3, 5: 5, 6: 5, 7: 7, 8: 7}\n",
    "    nobio_tags = [bio_to_nobio[tag] for tag in ex['ner_tags']]\n",
    "    return f\"\"\"Tokens: {ex['tokens']}\n",
    "    POS tags: {ex['pos_tags']}\n",
    "    NER tags: {nobio_tags}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b653c",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Vanilla\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bce559",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60d9b7",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Vanilla with no BIO tagging\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf8c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'PER': 1, 'ORG': 3, 'LOC': 5, 'MISC': 7}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f75118",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Word-level named entity reflection (doesn't work well)\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    For each word in the text, generate a short summary (maximum 10 words) reasoning about its possible named entity category.\n",
    "    Respond ONLY with:\n",
    "    1)explanation for each word.\n",
    "    2)ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_WLNER.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c922a",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Word-level named entity reflection with no BIO tagging\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a8d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'PER': 1, 'ORG': 3, 'LOC': 5, 'MISC': 7}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    For each word in the text, generate a short summary (maximum 10 words) reasoning about its possible named entity category.\n",
    "    Respond ONLY with:\n",
    "    1)explanation for each word.\n",
    "    2)ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_WLNER_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394a8c7",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Multi-turn adaptive refinement (works a bit better than simple vanilla with 300 samples, worse with 100 samples)\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    First, extract potential named entities, then refine the list by validating their relationships within the text.\n",
    "    Finally, consolidate the results.\n",
    "\n",
    "    Respond ONLY with:\n",
    "    1)the explanation as indicated above.\n",
    "    2)ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_MTAR.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926cc954",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Multi-turn adaptive refinement with no BIO tagging\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'PER': 1, 'ORG': 3, 'LOC': 5, 'MISC': 7}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    First, extract potential named entities, then refine the list by validating their relationships within the text.\n",
    "    Finally, consolidate the results.\n",
    "\n",
    "    Respond ONLY with:\n",
    "    1)the explanation as indicated above.\n",
    "    2)ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_MTAR_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e11d5",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Dependency-based entity validation (doesn't work well)\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66216a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    You are also given the dependency tree of the sentence in the following format:\n",
    "    {dependency_tree_str}\n",
    "\n",
    "    First, extract potential named entities based on the tokens.\n",
    "    Then, refine and validate the entities by analyzing their syntactic relationships according to the dependency tree.\n",
    "    Finally, consolidate the results into a final tagging.\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_DBEV.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ef1b7",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Dependency-based entity validation with no BIO \n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7340289",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'PER': 1, 'ORG': 3, 'LOC': 5, 'MISC': 7}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    This sentence contains exactly {len(tokens)} tokens.\n",
    "\n",
    "    You are also given the dependency tree of the sentence in the following format:\n",
    "    {dependency_tree_str}\n",
    "\n",
    "    First, extract potential named entities based on the tokens.\n",
    "    Then, refine and validate the entities by analyzing their syntactic relationships according to the dependency tree.\n",
    "    Finally, consolidate the results into a final tagging.\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_DBEV_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc22e2d8",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "POS-guided named entity recognition (works better than vanilla, but with BIO included)\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_POSGNER.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefdf36",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "POS-guided named entity recognition with no BIO tagging\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'PER': 1, 'ORG': 3, 'LOC': 5, 'MISC': 7}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_POSGNER_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45583d4e",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "POS-dependency hybrid NER (doesn't work well)\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "        \n",
    "    You are also given the dependency tree of the sentence in the following format:\n",
    "    {dependency_tree_str}\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_POSDHNER.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e773c60",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "POS-dependency hybrid NER with no BIO tagging\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2194843",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'PER': 1, 'ORG': 3, 'LOC': 5, 'MISC': 7}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "        \n",
    "    You are also given the dependency tree of the sentence in the following format:\n",
    "    {dependency_tree_str}\n",
    "\n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_POSDHNER_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be453595",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Example-driven POS NER\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75219d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "        \n",
    "    You are also given three correct examples.\n",
    "    Here are three correct examples:\n",
    "\n",
    "    Example 1:\n",
    "    {format_example(example1)}\n",
    "\n",
    "    Example 2:\n",
    "    {format_example(example2)}\n",
    "\n",
    "    Example 3:\n",
    "    {format_example(example3)}\n",
    "        \n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_EDPOSNER.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21e5c3",
   "metadata": {},
   "source": [
    "********************************************************************************************************************\n",
    "Example-driven POS NER with no BIO tagging\n",
    "********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(sampled_test_data)):\n",
    "    tokens = sampled_test_data[j]['tokens']\n",
    "    pos_tags = sampled_test_data[j]['pos_tags']\n",
    "    true_labels = sampled_test_data[j]['ner_tags']\n",
    "    dependency_tree = dependency_trees[j]\n",
    "\n",
    "    # Convert dependency_tree to JSON string\n",
    "    dependency_tree_str = json.dumps(dependency_tree, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"You are a strict NER tagging system.\n",
    "\n",
    "    Given the following NER tags:\n",
    "    {{'O': 0, 'PER': 1, 'ORG': 3, 'LOC': 5, 'MISC': 7}}\n",
    "\n",
    "    Your task is to assign the correct tag number to each token in this sentence:\n",
    "    {tokens}\n",
    "\n",
    "    You are also given the POS tag (part-of-speech) for each token.\n",
    "    POS tags (in order, one per token):\n",
    "    {pos_tags}\n",
    "        \n",
    "    You are also given three correct examples.\n",
    "    Here are three correct examples:\n",
    "\n",
    "    Example 1:\n",
    "    {format_example(example1)}\n",
    "\n",
    "    Example 2:\n",
    "    {format_example(example2)}\n",
    "\n",
    "    Example 3:\n",
    "    {format_example(example3)}\n",
    "        \n",
    "    Respond ONLY with:\n",
    "    ner_tags: x, x, x, ..., x  ← (exactly {len(tokens)} integers)\n",
    "\n",
    "    Do NOT include explanations, thoughts, or any other content.\n",
    "    Do NOT write anything before or after \"ner_tags: ...\".\n",
    "    Just print the sequence in the format specified.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=\"deepseek-r1:14b\", prompt=prompt)\n",
    "        raw_text = response.response\n",
    "        pred_tags_str = clean_response(raw_text)\n",
    "\n",
    "        # Parsing (conversion and validation)\n",
    "        parsed_data = parse_response_no_bio(tokens, f\"ner_tags: {','.join(pred_tags_str)}\", true_labels)\n",
    "\n",
    "        # Debug print\n",
    "        print(f\"[✓] Sentence {j}\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"Predicted: \", [x[1] for x in parsed_data])\n",
    "        print(\"True:      \", [x[2] for x in parsed_data])\n",
    "        print(\"---\")\n",
    "\n",
    "        # Save to file\n",
    "        save_to_csv_vanilla(tokens, [x[1] for x in parsed_data], true_labels, \"data100_ds/vanilla_test_100_ds_14b_EDPOSNER_NOBIO.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error at sentence {j}: {e}\")\n",
    "        print(f\"Raw response: {response.response if 'response' in locals() else 'None'}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data100_ds/vanilla_test_100_ds_14b_EDPOSNER_NOBIO_ONEEX.csv'\n",
    "\n",
    "# Corrects predicted values if they fall outside the range [0, 8], sets them to 0 (which is not counted in the evaluation)\n",
    "rows = []\n",
    "with open(filename, newline='', encoding='utf-8') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames\n",
    "    for row in reader:\n",
    "        try:\n",
    "            pred = int(row['pred'])\n",
    "        except ValueError:\n",
    "            pred = 0\n",
    "        if pred < 0 or pred > 8:\n",
    "            pred = 0\n",
    "        row['pred'] = str(pred)\n",
    "        rows.append(row)\n",
    "\n",
    "\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40747f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "label_mapping = {\n",
    "    0: 'O',\n",
    "    1: 'B-PER',\n",
    "    2: 'I-PER',\n",
    "    3: 'B-ORG',\n",
    "    4: 'I-ORG',\n",
    "    5: 'B-LOC',\n",
    "    6: 'I-LOC',\n",
    "    7: 'B-MISC',\n",
    "    8: 'I-MISC'\n",
    "}\n",
    "\n",
    "category_to_index = {\n",
    "    'O': 0,\n",
    "    'B-PER': 1, \n",
    "    'I-PER': 2, \n",
    "    'B-ORG': 3, \n",
    "    'I-ORG': 4, \n",
    "    'B-LOC': 5, \n",
    "    'I-LOC': 6, \n",
    "    'B-MISC': 7, \n",
    "    'I-MISC': 8\n",
    "    }\n",
    "\n",
    "# Step 2: Read the CSV and convert predictions and true labels\n",
    "true_seqs = []\n",
    "pred_seqs = []\n",
    "current_true = []\n",
    "current_pred = []\n",
    "\n",
    "with open('data100_ds/vanilla_test_100_ds_14b_EDPOSNER_NOBIO.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        token = row['token']                                                                                                                                                                                                                                                                                                                    \n",
    "        # true_label = index_to_label[int(row['true'])]\n",
    "        # pred_label = index_to_label[int(row['pred'])]\n",
    "        true_label = label_mapping[int(row['true'])]\n",
    "        pred_label = label_mapping[int(row['pred'])]\n",
    "\n",
    "        current_true.append(true_label)\n",
    "        current_pred.append(pred_label)\n",
    "\n",
    "    true_seqs.append(current_true)\n",
    "    pred_seqs.append(current_pred)\n",
    "\n",
    "# Step 3: Compute metrics\n",
    "print(\"Precision:\", precision_score(true_seqs, pred_seqs))\n",
    "print(\"Recall:\", recall_score(true_seqs, pred_seqs))\n",
    "print(\"F1 Score:\", f1_score(true_seqs, pred_seqs))\n",
    "\n",
    "# Optional detailed report\n",
    "print(\"\\nDetailed classification report:\\n\")\n",
    "print(classification_report(true_seqs, pred_seqs))\n",
    "#vanilla_test_100_ds_14b_POSGNER :  0.5042492917847027 \n",
    "\n",
    "#vanilla_test_100_ds_14b_EDPOSNER : F1 Score: 0.3553008595988538\n",
    "#vanilla_test_100_ds_14b_EDPOSNER_NOBIO : F1 Score: 0.46511627906976744"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insetti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
